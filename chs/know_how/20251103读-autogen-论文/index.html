<!doctype html><html lang=chs itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link rel=icon href=../../../favicon.svg><title>2025-11-03 读 AutoGen 论文 - 徐慧志的个人博客</title><meta name=description content="最近微软把AutoGen和Semantic Kernel 整合到一个框架了，叫做 Agent Framework。这两个框架，之前一个负责多智能体协作，一个负责写胶水代码，提供流程框架和中间件。
最近看了看AutoGen的论文，主要为了搞清楚它的智能体是如何协作运行的。下面介绍一下原理。
1. 什么是AutoGen？
简单来说，AutoGen就是一个让多个AI智能体能够互相聊天、合作的框架。
1.1 核心需求
AutoGen的设计目标是构建一个多智能体对话框架，具有通用抽象和有效实现，同时具备满足不同应用需求的灵活性。该框架需要考虑两个关键问题：
1.在多智能体协作中，单个智能体如何实现可用、可复用、定制化和高效？
2.如何开发一个能够适应多种智能体对话模式的统一接口？
1.2 技术可行性
AutoGen的提出基于三个关键的技术可行性因素。
首先，大语言模型具备整合反馈信息的能力，这些反馈可以来源于人类或者其他智能体。
其次，智能体能够提供或者接收推理、观察、评价和验证。
最后，在对话过程中，参与者能够提供分析和评价性反馈。基于这三点可以让多智能体协作。
2. 核心概念
2.1 可定制化智能体（Customizable and conversable agents）
AutoGen的核心概念是可定制化和可对话的智能体。Customizable and conversable agents具备两个关键特性：可定制性意味着可以根据需求选择不同的能力；可对话性则指智能体能够接收、反应和响应消息。
2.2 对话编程范式（Conversation programming）
AutoGen提出了一种以智能体间对话为中心的编程范式，这种范式能够简化开发流程，提高效率。对话编程需要考虑两个核心要素：
1.定义具有特定能力和角色的可对话智能体集合
2.通过以对话为中心的计算和控制来编程智能体间的交互行为
3. 智能体能力体系
3.1 三大能力来源
AutoGen的智能体能力由三大来源驱动：大型语言模型、人类和工具。
3.1.1 大型语言模型能力
基于LLM的智能体能够利用高级大型语言模型的多种能力，包括角色扮演、隐性状态推断和在对话历史条件下取得进展的能力。在接口层面，系统还提供结果缓存、错误处理、消息模板等功能。
3.1.2 人类参与能力
AutoGen通过人类支持的智能体在智能体对话中引入人类参与。通过配置可以设置参与的程度和模式。人类支持的智能体在对话过程中根据代理配置征求人类输入。
3.1.3 工具执行能力
工具支持的智能体可以执行各种工具，例如执行代码或者函数，扩展了智能体的功能边界。
3.2 智能体分类体系
AutoGen建立了完整的智能体分类体系：

ConversableAgent：最高层级的智能体抽象，可以使用LLM、人类和工具
AssistantAgent：ConversableAgent的子类，专门用于AI助手功能
UserProxyAgent：ConversableAgent的子类，用于征求人类输入和执行工具
GroupChatManager：用于管理群组对话的专门组件

4. 对话编程机制
4.1 编程模式
对话编程范式需要考虑两个关键维度：
1.计算（Computation）：多智能体对话中智能体为计算响应所采取的行动
2.控制流（Control Flow）：计算发生的条件
4.2 自动回复机制
AutoGen的核心创新在于实现了统一接口和自动回复机制，使聊天自动化成为可能。该机制包括send、receive和generate_reply三个核心功能。一旦对话开始，系统可以自动运行，无需额外控制。
智能体自动回复机制是AutoGen的核心特性："><meta name=generator content="Hugo 0.152.2"><link rel=stylesheet href="/css/styles.min.cc1204abf55b2794a944c9970dcfbbedd8cddb0c0451f7d9b088371efe0b6248.css" integrity crossorigin=anonymous><meta property="og:url" content="https://huizhixu.github.io/chs/know_how/20251103%E8%AF%BB-autogen-%E8%AE%BA%E6%96%87/"><meta property="og:site_name" content="徐慧志的个人博客"><meta property="og:title" content="2025-11-03 读 AutoGen 论文"><meta property="og:description" content="最近微软把AutoGen和Semantic Kernel 整合到一个框架了，叫做 Agent Framework。这两个框架，之前一个负责多智能体协作，一个负责写胶水代码，提供流程框架和中间件。
最近看了看AutoGen的论文，主要为了搞清楚它的智能体是如何协作运行的。下面介绍一下原理。
1. 什么是AutoGen？ 简单来说，AutoGen就是一个让多个AI智能体能够互相聊天、合作的框架。
1.1 核心需求 AutoGen的设计目标是构建一个多智能体对话框架，具有通用抽象和有效实现，同时具备满足不同应用需求的灵活性。该框架需要考虑两个关键问题：
1.在多智能体协作中，单个智能体如何实现可用、可复用、定制化和高效？
2.如何开发一个能够适应多种智能体对话模式的统一接口？
1.2 技术可行性 AutoGen的提出基于三个关键的技术可行性因素。
首先，大语言模型具备整合反馈信息的能力，这些反馈可以来源于人类或者其他智能体。
其次，智能体能够提供或者接收推理、观察、评价和验证。
最后，在对话过程中，参与者能够提供分析和评价性反馈。基于这三点可以让多智能体协作。
2. 核心概念 2.1 可定制化智能体（Customizable and conversable agents） AutoGen的核心概念是可定制化和可对话的智能体。Customizable and conversable agents具备两个关键特性：可定制性意味着可以根据需求选择不同的能力；可对话性则指智能体能够接收、反应和响应消息。
2.2 对话编程范式（Conversation programming） AutoGen提出了一种以智能体间对话为中心的编程范式，这种范式能够简化开发流程，提高效率。对话编程需要考虑两个核心要素：
1.定义具有特定能力和角色的可对话智能体集合
2.通过以对话为中心的计算和控制来编程智能体间的交互行为
3. 智能体能力体系 3.1 三大能力来源 AutoGen的智能体能力由三大来源驱动：大型语言模型、人类和工具。
3.1.1 大型语言模型能力 基于LLM的智能体能够利用高级大型语言模型的多种能力，包括角色扮演、隐性状态推断和在对话历史条件下取得进展的能力。在接口层面，系统还提供结果缓存、错误处理、消息模板等功能。
3.1.2 人类参与能力 AutoGen通过人类支持的智能体在智能体对话中引入人类参与。通过配置可以设置参与的程度和模式。人类支持的智能体在对话过程中根据代理配置征求人类输入。
3.1.3 工具执行能力 工具支持的智能体可以执行各种工具，例如执行代码或者函数，扩展了智能体的功能边界。
3.2 智能体分类体系 AutoGen建立了完整的智能体分类体系：
ConversableAgent：最高层级的智能体抽象，可以使用LLM、人类和工具 AssistantAgent：ConversableAgent的子类，专门用于AI助手功能 UserProxyAgent：ConversableAgent的子类，用于征求人类输入和执行工具 GroupChatManager：用于管理群组对话的专门组件 4. 对话编程机制 4.1 编程模式 对话编程范式需要考虑两个关键维度：
1.计算（Computation）：多智能体对话中智能体为计算响应所采取的行动
2.控制流（Control Flow）：计算发生的条件
4.2 自动回复机制 AutoGen的核心创新在于实现了统一接口和自动回复机制，使聊天自动化成为可能。该机制包括send、receive和generate_reply三个核心功能。一旦对话开始，系统可以自动运行，无需额外控制。
智能体自动回复机制是AutoGen的核心特性："><meta property="og:locale" content="chs"><meta property="og:type" content="article"><meta property="article:section" content="know_how"><meta property="article:published_time" content="2025-11-03T13:55:08+00:00"><meta property="article:modified_time" content="2025-11-03T13:55:08+00:00"><meta property="article:tag" content="Tech"><meta name=twitter:card content="summary"><meta name=twitter:title content="2025-11-03 读 AutoGen 论文"><meta name=twitter:description content="最近微软把AutoGen和Semantic Kernel 整合到一个框架了，叫做 Agent Framework。这两个框架，之前一个负责多智能体协作，一个负责写胶水代码，提供流程框架和中间件。
最近看了看AutoGen的论文，主要为了搞清楚它的智能体是如何协作运行的。下面介绍一下原理。
1. 什么是AutoGen？ 简单来说，AutoGen就是一个让多个AI智能体能够互相聊天、合作的框架。
1.1 核心需求 AutoGen的设计目标是构建一个多智能体对话框架，具有通用抽象和有效实现，同时具备满足不同应用需求的灵活性。该框架需要考虑两个关键问题：
1.在多智能体协作中，单个智能体如何实现可用、可复用、定制化和高效？
2.如何开发一个能够适应多种智能体对话模式的统一接口？
1.2 技术可行性 AutoGen的提出基于三个关键的技术可行性因素。
首先，大语言模型具备整合反馈信息的能力，这些反馈可以来源于人类或者其他智能体。
其次，智能体能够提供或者接收推理、观察、评价和验证。
最后，在对话过程中，参与者能够提供分析和评价性反馈。基于这三点可以让多智能体协作。
2. 核心概念 2.1 可定制化智能体（Customizable and conversable agents） AutoGen的核心概念是可定制化和可对话的智能体。Customizable and conversable agents具备两个关键特性：可定制性意味着可以根据需求选择不同的能力；可对话性则指智能体能够接收、反应和响应消息。
2.2 对话编程范式（Conversation programming） AutoGen提出了一种以智能体间对话为中心的编程范式，这种范式能够简化开发流程，提高效率。对话编程需要考虑两个核心要素：
1.定义具有特定能力和角色的可对话智能体集合
2.通过以对话为中心的计算和控制来编程智能体间的交互行为
3. 智能体能力体系 3.1 三大能力来源 AutoGen的智能体能力由三大来源驱动：大型语言模型、人类和工具。
3.1.1 大型语言模型能力 基于LLM的智能体能够利用高级大型语言模型的多种能力，包括角色扮演、隐性状态推断和在对话历史条件下取得进展的能力。在接口层面，系统还提供结果缓存、错误处理、消息模板等功能。
3.1.2 人类参与能力 AutoGen通过人类支持的智能体在智能体对话中引入人类参与。通过配置可以设置参与的程度和模式。人类支持的智能体在对话过程中根据代理配置征求人类输入。
3.1.3 工具执行能力 工具支持的智能体可以执行各种工具，例如执行代码或者函数，扩展了智能体的功能边界。
3.2 智能体分类体系 AutoGen建立了完整的智能体分类体系：
ConversableAgent：最高层级的智能体抽象，可以使用LLM、人类和工具 AssistantAgent：ConversableAgent的子类，专门用于AI助手功能 UserProxyAgent：ConversableAgent的子类，用于征求人类输入和执行工具 GroupChatManager：用于管理群组对话的专门组件 4. 对话编程机制 4.1 编程模式 对话编程范式需要考虑两个关键维度：
1.计算（Computation）：多智能体对话中智能体为计算响应所采取的行动
2.控制流（Control Flow）：计算发生的条件
4.2 自动回复机制 AutoGen的核心创新在于实现了统一接口和自动回复机制，使聊天自动化成为可能。该机制包括send、receive和generate_reply三个核心功能。一旦对话开始，系统可以自动运行，无需额外控制。
智能体自动回复机制是AutoGen的核心特性："><meta itemprop=name content="2025-11-03 读 AutoGen 论文"><meta itemprop=description content="最近微软把AutoGen和Semantic Kernel 整合到一个框架了，叫做 Agent Framework。这两个框架，之前一个负责多智能体协作，一个负责写胶水代码，提供流程框架和中间件。
最近看了看AutoGen的论文，主要为了搞清楚它的智能体是如何协作运行的。下面介绍一下原理。
1. 什么是AutoGen？ 简单来说，AutoGen就是一个让多个AI智能体能够互相聊天、合作的框架。
1.1 核心需求 AutoGen的设计目标是构建一个多智能体对话框架，具有通用抽象和有效实现，同时具备满足不同应用需求的灵活性。该框架需要考虑两个关键问题：
1.在多智能体协作中，单个智能体如何实现可用、可复用、定制化和高效？
2.如何开发一个能够适应多种智能体对话模式的统一接口？
1.2 技术可行性 AutoGen的提出基于三个关键的技术可行性因素。
首先，大语言模型具备整合反馈信息的能力，这些反馈可以来源于人类或者其他智能体。
其次，智能体能够提供或者接收推理、观察、评价和验证。
最后，在对话过程中，参与者能够提供分析和评价性反馈。基于这三点可以让多智能体协作。
2. 核心概念 2.1 可定制化智能体（Customizable and conversable agents） AutoGen的核心概念是可定制化和可对话的智能体。Customizable and conversable agents具备两个关键特性：可定制性意味着可以根据需求选择不同的能力；可对话性则指智能体能够接收、反应和响应消息。
2.2 对话编程范式（Conversation programming） AutoGen提出了一种以智能体间对话为中心的编程范式，这种范式能够简化开发流程，提高效率。对话编程需要考虑两个核心要素：
1.定义具有特定能力和角色的可对话智能体集合
2.通过以对话为中心的计算和控制来编程智能体间的交互行为
3. 智能体能力体系 3.1 三大能力来源 AutoGen的智能体能力由三大来源驱动：大型语言模型、人类和工具。
3.1.1 大型语言模型能力 基于LLM的智能体能够利用高级大型语言模型的多种能力，包括角色扮演、隐性状态推断和在对话历史条件下取得进展的能力。在接口层面，系统还提供结果缓存、错误处理、消息模板等功能。
3.1.2 人类参与能力 AutoGen通过人类支持的智能体在智能体对话中引入人类参与。通过配置可以设置参与的程度和模式。人类支持的智能体在对话过程中根据代理配置征求人类输入。
3.1.3 工具执行能力 工具支持的智能体可以执行各种工具，例如执行代码或者函数，扩展了智能体的功能边界。
3.2 智能体分类体系 AutoGen建立了完整的智能体分类体系：
ConversableAgent：最高层级的智能体抽象，可以使用LLM、人类和工具 AssistantAgent：ConversableAgent的子类，专门用于AI助手功能 UserProxyAgent：ConversableAgent的子类，用于征求人类输入和执行工具 GroupChatManager：用于管理群组对话的专门组件 4. 对话编程机制 4.1 编程模式 对话编程范式需要考虑两个关键维度：
1.计算（Computation）：多智能体对话中智能体为计算响应所采取的行动
2.控制流（Control Flow）：计算发生的条件
4.2 自动回复机制 AutoGen的核心创新在于实现了统一接口和自动回复机制，使聊天自动化成为可能。该机制包括send、receive和generate_reply三个核心功能。一旦对话开始，系统可以自动运行，无需额外控制。
智能体自动回复机制是AutoGen的核心特性："><meta itemprop=datePublished content="2025-11-03T13:55:08+00:00"><meta itemprop=dateModified content="2025-11-03T13:55:08+00:00"><meta itemprop=wordCount content="88"><meta itemprop=keywords content="Tech"><meta name=lang content="chs"></head><body class="dark:bg-gray-800 dark:text-white relative flex flex-col min-h-screen"><header class="container flex justify-between md:justify-between gap-4 flex-wrap p-6 mx-auto relative"><a href=https://huizhixu.github.io/chs/ class="capitalize font-extrabold text-2xl"><img src=../../../blist-logo.png alt=徐慧志的个人博客 class="h-8 max-w-full">
</a><button class="mobile-menu-button md:hidden">
<svg width="30" height="30" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><line x1="4" y1="8" x2="20" y2="8"/><line x1="4" y1="16" x2="20" y2="16"/></svg></button><ul class="mobile-menu absolute z-10 px-6 pb-6 md:p-0 top-full left-0 w-full md:w-auto md:relative hidden md:flex flex-col md:flex-row items-end md:items-center gap-4 lg:gap-6 bg-white dark:bg-gray-800"><li><a href=../../../chs/know_how/>技术</a></li><li><a href=../../../chs/life/>生活见闻</a></li><li><a href=../../../chs/page/about/>关于</a></li><li><a href=../../../chs/link/>宝藏集结</a></li><li><a href=../../../chs/tags/>分类</a></li><li class="relative cursor-pointer"><span class="language-switcher flex items-center gap-2"><svg width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="12" cy="12" r="9"/><line x1="3.6" y1="9" x2="20.4" y2="9"/><line x1="3.6" y1="15" x2="20.4" y2="15"/><path d="M11.5 3a17 17 0 000 18"/><path d="M12.5 3a17 17 0 010 18"/></svg>
<a>语言</a>
<svg width="14" height="14" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M18 15l-6-6-6 6h12" transform="rotate(180 12 12)"/></svg></span><div class="language-dropdown absolute top-full mt-2 left-0 flex-col gap-2 bg-gray-100 dark:bg-gray-900 dark:text-white z-10 hidden"><a class="px-3 py-2 hover:bg-gray-200 dark:hover:bg-gray-700" href=../../../en/ lang=en>English</a>
<a class="px-3 py-2 hover:bg-gray-200 dark:hover:bg-gray-700" href=../../../de/ lang=de>Deutsch</a></div></li><li class="grid place-items-center"><span class="open-search inline-block cursor-pointer"><svg width="20" height="20" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg></span></li><li class="grid place-items-center"><span class="toggle-dark-mode inline-block cursor-pointer"><svg width="24" height="24" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="12" cy="12" r="3"/><line x1="12" y1="5" x2="12" y2="5.01"/><line x1="17" y1="7" x2="17" y2="7.01"/><line x1="19" y1="12" x2="19" y2="12.01"/><line x1="17" y1="17" x2="17" y2="17.01"/><line x1="12" y1="19" x2="12" y2="19.01"/><line x1="7" y1="17" x2="7" y2="17.01"/><line x1="5" y1="12" x2="5" y2="12.01"/><line x1="7" y1="7" x2="7" y2="7.01"/></svg></span></li></ul></header><main class=flex-1><article class="prose lg:prose-lg mx-auto my-8 dark:prose-dark px-4"><h1 class="text-2xl font-bold mb-2">2025-11-03 读 AutoGen 论文</h1><h5 class="text-sm flex items-center flex-wrap"><svg class="mr-1" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><rect x="4" y="5" width="16" height="16" rx="2"/><line x1="16" y1="3" x2="16" y2="7"/><line x1="8" y1="3" x2="8" y2="7"/><line x1="4" y1="11" x2="20" y2="11"/><rect x="8" y="15" width="2" height="2"/></svg>
发布于
2025年11月03日
&nbsp;&bull;&nbsp;
<svg class="mr-1" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
1&nbsp;分钟
&nbsp;&bull;
<svg class="mx-1" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M3 19a9 9 0 019 0 9 9 0 019 0"/><path d="M3 6a9 9 0 019 0 9 9 0 019 0"/><line x1="3" y1="6" x2="3" y2="19"/><line x1="12" y1="6" x2="12" y2="19"/><line x1="21" y1="6" x2="21" y2="19"/></svg>
88&nbsp;字</h5><details id=TableOfContents class="px-4 mt-4 bg-gray-100 dark:bg-gray-700 rounded toc"><summary class="flex items-center font-bold py-2 px-4 cursor-pointer justify-between select-none text-black dark:text-white"><span>Table of contents</span>
<svg class="icon icon-tabler icon-tabler-chevron-down" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><polyline points="6 9 12 15 18 9"/></svg></summary><ul class="mt-2 pb-4"><li><a href=#1-%e4%bb%80%e4%b9%88%e6%98%afautogen>1. 什么是AutoGen？</a><ul><li><a href=#11-%e6%a0%b8%e5%bf%83%e9%9c%80%e6%b1%82>1.1 核心需求</a></li><li><a href=#12-%e6%8a%80%e6%9c%af%e5%8f%af%e8%a1%8c%e6%80%a7>1.2 技术可行性</a></li></ul></li><li><a href=#2-%e6%a0%b8%e5%bf%83%e6%a6%82%e5%bf%b5>2. 核心概念</a><ul><li><a href=#21-%e5%8f%af%e5%ae%9a%e5%88%b6%e5%8c%96%e6%99%ba%e8%83%bd%e4%bd%93customizable-and-conversable-agents>2.1 可定制化智能体（Customizable and conversable agents）</a></li><li><a href=#22-%e5%af%b9%e8%af%9d%e7%bc%96%e7%a8%8b%e8%8c%83%e5%bc%8fconversation-programming>2.2 对话编程范式（Conversation programming）</a></li></ul></li><li><a href=#3-%e6%99%ba%e8%83%bd%e4%bd%93%e8%83%bd%e5%8a%9b%e4%bd%93%e7%b3%bb>3. 智能体能力体系</a><ul><li><a href=#31-%e4%b8%89%e5%a4%a7%e8%83%bd%e5%8a%9b%e6%9d%a5%e6%ba%90>3.1 三大能力来源</a></li><li><a href=#311-%e5%a4%a7%e5%9e%8b%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e8%83%bd%e5%8a%9b>3.1.1 大型语言模型能力</a></li><li><a href=#312-%e4%ba%ba%e7%b1%bb%e5%8f%82%e4%b8%8e%e8%83%bd%e5%8a%9b>3.1.2 人类参与能力</a></li><li><a href=#313-%e5%b7%a5%e5%85%b7%e6%89%a7%e8%a1%8c%e8%83%bd%e5%8a%9b>3.1.3 工具执行能力</a></li><li><a href=#32-%e6%99%ba%e8%83%bd%e4%bd%93%e5%88%86%e7%b1%bb%e4%bd%93%e7%b3%bb>3.2 智能体分类体系</a></li></ul></li><li><a href=#4-%e5%af%b9%e8%af%9d%e7%bc%96%e7%a8%8b%e6%9c%ba%e5%88%b6>4. 对话编程机制</a><ul><li><a href=#41-%e7%bc%96%e7%a8%8b%e6%a8%a1%e5%bc%8f>4.1 编程模式</a></li><li><a href=#42-%e8%87%aa%e5%8a%a8%e5%9b%9e%e5%a4%8d%e6%9c%ba%e5%88%b6>4.2 自动回复机制</a></li><li><a href=#43-%e6%8e%a7%e5%88%b6%e6%9c%ba%e5%88%b6>4.3 控制机制</a></li></ul></li><li><a href=#5-%e6%80%bb%e7%bb%93>5. 总结</a></li></ul></details><p>最近微软把AutoGen和Semantic Kernel 整合到一个框架了，叫做 Agent Framework。这两个框架，之前一个负责多智能体协作，一个负责写胶水代码，提供流程框架和中间件。</p><p>最近看了看AutoGen的论文，主要为了搞清楚它的智能体是如何协作运行的。下面介绍一下原理。</p><h2 id=1-什么是autogen>1. 什么是AutoGen？</h2><p>简单来说，AutoGen就是一个让多个AI智能体能够互相聊天、合作的框架。</p><h3 id=11-核心需求>1.1 核心需求</h3><p>AutoGen的设计目标是构建一个多智能体对话框架，具有通用抽象和有效实现，同时具备满足不同应用需求的灵活性。该框架需要考虑两个关键问题：</p><p>1.在多智能体协作中，单个智能体如何实现可用、可复用、定制化和高效？</p><p>2.如何开发一个能够适应多种智能体对话模式的统一接口？</p><h3 id=12-技术可行性>1.2 技术可行性</h3><p>AutoGen的提出基于三个关键的技术可行性因素。</p><p>首先，大语言模型具备整合反馈信息的能力，这些反馈可以来源于人类或者其他智能体。</p><p>其次，智能体能够提供或者接收推理、观察、评价和验证。</p><p>最后，在对话过程中，参与者能够提供分析和评价性反馈。基于这三点可以让多智能体协作。</p><h2 id=2-核心概念>2. 核心概念</h2><h3 id=21-可定制化智能体customizable-and-conversable-agents>2.1 可定制化智能体（Customizable and conversable agents）</h3><p>AutoGen的核心概念是可定制化和可对话的智能体。Customizable and conversable agents具备两个关键特性：可定制性意味着可以根据需求选择不同的能力；可对话性则指智能体能够接收、反应和响应消息。</p><h3 id=22-对话编程范式conversation-programming>2.2 对话编程范式（Conversation programming）</h3><p>AutoGen提出了一种以智能体间对话为中心的编程范式，这种范式能够简化开发流程，提高效率。对话编程需要考虑两个核心要素：</p><p>1.定义具有特定能力和角色的可对话智能体集合</p><p>2.通过以对话为中心的计算和控制来编程智能体间的交互行为</p><h2 id=3-智能体能力体系>3. 智能体能力体系</h2><h3 id=31-三大能力来源>3.1 三大能力来源</h3><p>AutoGen的智能体能力由三大来源驱动：大型语言模型、人类和工具。</p><h3 id=311-大型语言模型能力>3.1.1 大型语言模型能力</h3><p>基于LLM的智能体能够利用高级大型语言模型的多种能力，包括角色扮演、隐性状态推断和在对话历史条件下取得进展的能力。在接口层面，系统还提供结果缓存、错误处理、消息模板等功能。</p><h3 id=312-人类参与能力>3.1.2 人类参与能力</h3><p>AutoGen通过人类支持的智能体在智能体对话中引入人类参与。通过配置可以设置参与的程度和模式。人类支持的智能体在对话过程中根据代理配置征求人类输入。</p><h3 id=313-工具执行能力>3.1.3 工具执行能力</h3><p>工具支持的智能体可以执行各种工具，例如执行代码或者函数，扩展了智能体的功能边界。</p><h3 id=32-智能体分类体系>3.2 智能体分类体系</h3><p>AutoGen建立了完整的智能体分类体系：</p><ul><li>ConversableAgent：最高层级的智能体抽象，可以使用LLM、人类和工具</li><li>AssistantAgent：ConversableAgent的子类，专门用于AI助手功能</li><li>UserProxyAgent：ConversableAgent的子类，用于征求人类输入和执行工具</li><li>GroupChatManager：用于管理群组对话的专门组件</li></ul><h2 id=4-对话编程机制>4. 对话编程机制</h2><h3 id=41-编程模式>4.1 编程模式</h3><p>对话编程范式需要考虑两个关键维度：</p><p>1.计算（Computation）：多智能体对话中智能体为计算响应所采取的行动</p><p>2.控制流（Control Flow）：计算发生的条件</p><h3 id=42-自动回复机制>4.2 自动回复机制</h3><p>AutoGen的核心创新在于实现了统一接口和自动回复机制，使聊天自动化成为可能。该机制包括send、receive和generate_reply三个核心功能。一旦对话开始，系统可以自动运行，无需额外控制。</p><p>智能体自动回复机制是AutoGen的核心特性：</p><ul><li>一旦某智能体收到来自另一智能体的消息，便自动调用generate_reply并将回复发回给对方，除非满足终止条件</li><li>AutoGen内置了基于LLM推理、代码或函数执行、人工输入的回复函数</li><li>系统支持注册自定义回复函数，以定制智能体的行为模式</li><li>例如，在回复发送方之前先与另一智能体对话</li><li>在该机制下，只要回复函数注册完毕且对话初始化完成，对话流便自然产生</li><li>智能体对话无需任何额外控制平面即可自然推进</li></ul><h3 id=43-控制机制>4.3 控制机制</h3><p>AutoGen通过编程和自然语言的融合实现控制，支持动态对话流，既支持预定义流程，也支持动态对话流。</p><h2 id=5-总结>5. 总结</h2><p>AutoGen 支持多个 AI 智能体通过对话协作完成任务。它不仅支持智能体之间的交互，还允许人类在关键环节介入，形成“人机协同”的工作流。</p><p>AutoGen的重点在于多智能体之间的交互，它最大的优势在于提供通信框架。</p><ol><li>定义不同的具有不同能力和角色的agents</li><li>通过以对话为中心的计算和控制来编程智能体之间的交互行为</li></ol></article><div class="px-2 mb-2"><script src=https://utteranc.es/client.js repo=HuizhiXu/huizhixu.github.io issue-term=pathname theme=github-light crossorigin=anonymous async></script></div><div class="bg-blue-100 dark:bg-gray-900"><div class="container px-4 py-12 mx-auto max-w-4xl grid grid-cols-1 md:grid-cols-2 gap-4 items-center"><div><div class="text-2xl font-bold mb-2">Sein heißt werden, leben heißt lernen.</div><p class=opacity-60>Der einfache Weg is immer verkehrt.</p></div><ul class="flex justify-center gap-x-3 flex-wrap gap-y-2"><li><a href=https://twitter.com/ target=_blank rel=noopener aria-label=Twitter class="p-1 inline-block rounded-full border border-transparent text-gray-500 hover:text-gray-800 hover:border-gray-800 cursor-pointer transition-colors dark:text-gray-600 dark:hover:border-gray-300 dark:hover:text-gray-300"><svg width="24" height="24" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M22 4.01c-1 .49-1.98.689-3 .99-1.121-1.265-2.783-1.335-4.38-.737S11.977 6.323 12 8v1c-3.245.083-6.135-1.395-8-4 0 0-4.182 7.433 4 11-1.872 1.247-3.739 2.088-6 2 3.308 1.803 6.913 2.423 10.034 1.517 3.58-1.04 6.522-3.723 7.651-7.742a13.84 13.84.0 00.497-3.753C20.18 7.773 21.692 5.25 22 4.009z"/></svg></a></li><li><a href=https://github.com/ target=_blank rel=noopener aria-label=GitHub class="p-1 inline-block rounded-full border border-transparent text-gray-500 hover:text-gray-800 hover:border-gray-800 cursor-pointer transition-colors dark:text-gray-600 dark:hover:border-gray-300 dark:hover:text-gray-300"><svg width="24" height="24" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ul></div></div></main><footer class="container p-6 mx-auto flex justify-between items-center"><span class="text-sm font-light">Copyright © 2012 - Huizhi Xu · All rights reserved
</span><span onclick='window.scrollTo({top:0,behavior:"smooth"})' class="p-1 cursor-pointer"><svg width="30" height="30" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M18 15l-6-6-6 6h12"/></svg></span></footer><div class="search-ui absolute top-0 left-0 w-full h-full bg-white dark:bg-gray-800 hidden"><div class="container max-w-3xl mx-auto p-12"><div class=relative><div class="my-4 text-center text-2xl font-bold">Search</div><span class="p-2 absolute right-0 top-0 cursor-pointer close-search"><svg width="24" height="24" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><line x1="18" y1="6" x2="6" y2="18"/><line x1="6" y1="6" x2="18" y2="18"/></svg></span></div><input type=search class="py-2 px-3 w-full dark:text-black border dark:border-transparent" placeholder="Enter search query"><div class="search-results text-lg font-medium my-4 hidden">Results</div><ul class="search-list my-2"></ul><div class="no-results text-center my-8 hidden"><div class="text-xl font-semibold mb-2">No results found</div><p class="font-light text-sm">Try adjusting your search query</p></div></div></div><script src=https://huizhixu.github.io/js/scripts.min.js></script><script>const languageMenuButton=document.querySelector(".language-switcher"),languageDropdown=document.querySelector(".language-dropdown");languageMenuButton.addEventListener("click",e=>{e.preventDefault(),languageDropdown.classList.contains("hidden")?(languageDropdown.classList.remove("hidden"),languageDropdown.classList.add("flex")):(languageDropdown.classList.add("hidden"),languageDropdown.classList.remove("flex"))})</script><script>const darkmode=document.querySelector(".toggle-dark-mode");function toggleDarkMode(){document.documentElement.classList.contains("dark")?(document.documentElement.classList.remove("dark"),localStorage.setItem("darkmode","light")):(document.documentElement.classList.add("dark"),localStorage.setItem("darkmode","dark"))}darkmode&&darkmode.addEventListener("click",toggleDarkMode);const darkStorage=localStorage.getItem("darkmode"),isBrowserDark=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches;!darkStorage&&isBrowserDark&&document.documentElement.classList.add("dark"),darkStorage&&darkStorage==="dark"&&toggleDarkMode()</script><script>const mobileMenuButton=document.querySelector(".mobile-menu-button"),mobileMenu=document.querySelector(".mobile-menu");function toggleMenu(){mobileMenu.classList.toggle("hidden"),mobileMenu.classList.toggle("flex")}mobileMenu&&mobileMenuButton&&mobileMenuButton.addEventListener("click",toggleMenu)</script></body></html>