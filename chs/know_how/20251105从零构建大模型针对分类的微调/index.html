<!doctype html><html lang=chs itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link rel=icon href=../../../favicon.svg><title>2025-11-05 从零构建大模型—针对分类的微调 - 徐慧志的个人博客</title><meta name=description content="这本书最后两章的例子9月底就运行完了，但是微信读书会员到期了。最近又开了会员复习了一遍，记录下来。
微调通常可分为以下三个阶段：
第一阶段：数据准备
包括下载数据集、进行数据预处理以及构建数据加载器。
第二阶段：模型准备
涵盖模型初始化、加载预训练权重、调整模型结构，并实现评估工具。
第三阶段：模型微调与部署
包括执行模型微调、评估微调效果，以及在新数据上进行推理。
在语言模型微调中，主要分为分类微调和指令微调两种类型。分类微调相对简单，例如在垃圾消息检测任务中，模型只需输出&#34;垃圾消息&#34;或&#34;非垃圾消息&#34;两类结果，适用于对分类精度要求较高的场景。本章重点在于通过调整模型结构来实现微调，因此可以重点关注模型结构的修改方法。
第一阶段：准备数据
1. 下载数据
网上有公开的垃圾邮件和非垃圾邮件数据集可供下载。
2. 数据集预处理
预处理时主要需要注意设置max_length进行截断和填充。另外，在分类任务中需要特别关注各类别数据的均衡性。
from uu import encode
import torch
from torch.utils.data import Dataset
import tiktoken
import pandas as pd

class SpamDataset(Dataset):
    def __init__(self, csv_file, tokenizer, max_len=200,pad_token_id=50256):
        self.csv_file = csv_file
        self.data = pd.read_csv(csv_file, sep='\\t')

        self.encoded_texts =[tokenizer.encode(text) for text in self.data['text']]
        self.max_len = max_len

        if self.max_len:
            processed_texts = []
            for encoded in self.encoded_texts:
                # 截断到最大长度
                truncated = encoded[:self.max_len]
                # 填充到最大长度
                padded = truncated + [pad_token_id] * (self.max_len - len(truncated))
                processed_texts.append(padded)
            self.encoded_texts = processed_texts

    def __getitem__(self, index):
        encoded = self.encoded_texts[index]
        label = self.data.iloc[index]['label']
        return (torch.tensor(encoded, dtype=torch.long), torch.tensor(label, dtype=torch.long))

    def __len__(self):
        return len(self.data)
3. 创建数据加载器
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_worker)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_worker)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_worker)
第二阶段：修改模型
1. 模型初始化
GPTModel是在《徒手组装GPT》章节中构建好的类。"><meta name=generator content="Hugo 0.152.2"><link rel=stylesheet href="/css/styles.min.cc1204abf55b2794a944c9970dcfbbedd8cddb0c0451f7d9b088371efe0b6248.css" integrity crossorigin=anonymous><meta property="og:url" content="https://huizhixu.github.io/chs/know_how/20251105%E4%BB%8E%E9%9B%B6%E6%9E%84%E5%BB%BA%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%92%88%E5%AF%B9%E5%88%86%E7%B1%BB%E7%9A%84%E5%BE%AE%E8%B0%83/"><meta property="og:site_name" content="徐慧志的个人博客"><meta property="og:title" content="2025-11-05 从零构建大模型—针对分类的微调"><meta property="og:description" content="这本书最后两章的例子9月底就运行完了，但是微信读书会员到期了。最近又开了会员复习了一遍，记录下来。
微调通常可分为以下三个阶段：
第一阶段：数据准备
包括下载数据集、进行数据预处理以及构建数据加载器。
第二阶段：模型准备
涵盖模型初始化、加载预训练权重、调整模型结构，并实现评估工具。
第三阶段：模型微调与部署
包括执行模型微调、评估微调效果，以及在新数据上进行推理。
在语言模型微调中，主要分为分类微调和指令微调两种类型。分类微调相对简单，例如在垃圾消息检测任务中，模型只需输出&#34;垃圾消息&#34;或&#34;非垃圾消息&#34;两类结果，适用于对分类精度要求较高的场景。本章重点在于通过调整模型结构来实现微调，因此可以重点关注模型结构的修改方法。
第一阶段：准备数据 1. 下载数据 网上有公开的垃圾邮件和非垃圾邮件数据集可供下载。
2. 数据集预处理 预处理时主要需要注意设置max_length进行截断和填充。另外，在分类任务中需要特别关注各类别数据的均衡性。
from uu import encode import torch from torch.utils.data import Dataset import tiktoken import pandas as pd class SpamDataset(Dataset): def __init__(self, csv_file, tokenizer, max_len=200,pad_token_id=50256): self.csv_file = csv_file self.data = pd.read_csv(csv_file, sep='\\t') self.encoded_texts =[tokenizer.encode(text) for text in self.data['text']] self.max_len = max_len if self.max_len: processed_texts = [] for encoded in self.encoded_texts: # 截断到最大长度 truncated = encoded[:self.max_len] # 填充到最大长度 padded = truncated + [pad_token_id] * (self.max_len - len(truncated)) processed_texts.append(padded) self.encoded_texts = processed_texts def __getitem__(self, index): encoded = self.encoded_texts[index] label = self.data.iloc[index]['label'] return (torch.tensor(encoded, dtype=torch.long), torch.tensor(label, dtype=torch.long)) def __len__(self): return len(self.data) 3. 创建数据加载器 train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_worker) val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_worker) test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_worker) 第二阶段：修改模型 1. 模型初始化 GPTModel是在《徒手组装GPT》章节中构建好的类。"><meta property="og:locale" content="chs"><meta property="og:type" content="article"><meta property="article:section" content="know_how"><meta property="article:published_time" content="2025-11-05T13:54:46+00:00"><meta property="article:modified_time" content="2025-11-05T13:54:46+00:00"><meta property="article:tag" content="Tech"><meta name=twitter:card content="summary"><meta name=twitter:title content="2025-11-05 从零构建大模型—针对分类的微调"><meta name=twitter:description content="这本书最后两章的例子9月底就运行完了，但是微信读书会员到期了。最近又开了会员复习了一遍，记录下来。
微调通常可分为以下三个阶段：
第一阶段：数据准备
包括下载数据集、进行数据预处理以及构建数据加载器。
第二阶段：模型准备
涵盖模型初始化、加载预训练权重、调整模型结构，并实现评估工具。
第三阶段：模型微调与部署
包括执行模型微调、评估微调效果，以及在新数据上进行推理。
在语言模型微调中，主要分为分类微调和指令微调两种类型。分类微调相对简单，例如在垃圾消息检测任务中，模型只需输出&#34;垃圾消息&#34;或&#34;非垃圾消息&#34;两类结果，适用于对分类精度要求较高的场景。本章重点在于通过调整模型结构来实现微调，因此可以重点关注模型结构的修改方法。
第一阶段：准备数据 1. 下载数据 网上有公开的垃圾邮件和非垃圾邮件数据集可供下载。
2. 数据集预处理 预处理时主要需要注意设置max_length进行截断和填充。另外，在分类任务中需要特别关注各类别数据的均衡性。
from uu import encode import torch from torch.utils.data import Dataset import tiktoken import pandas as pd class SpamDataset(Dataset): def __init__(self, csv_file, tokenizer, max_len=200,pad_token_id=50256): self.csv_file = csv_file self.data = pd.read_csv(csv_file, sep='\\t') self.encoded_texts =[tokenizer.encode(text) for text in self.data['text']] self.max_len = max_len if self.max_len: processed_texts = [] for encoded in self.encoded_texts: # 截断到最大长度 truncated = encoded[:self.max_len] # 填充到最大长度 padded = truncated + [pad_token_id] * (self.max_len - len(truncated)) processed_texts.append(padded) self.encoded_texts = processed_texts def __getitem__(self, index): encoded = self.encoded_texts[index] label = self.data.iloc[index]['label'] return (torch.tensor(encoded, dtype=torch.long), torch.tensor(label, dtype=torch.long)) def __len__(self): return len(self.data) 3. 创建数据加载器 train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_worker) val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_worker) test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_worker) 第二阶段：修改模型 1. 模型初始化 GPTModel是在《徒手组装GPT》章节中构建好的类。"><meta itemprop=name content="2025-11-05 从零构建大模型—针对分类的微调"><meta itemprop=description content="这本书最后两章的例子9月底就运行完了，但是微信读书会员到期了。最近又开了会员复习了一遍，记录下来。
微调通常可分为以下三个阶段：
第一阶段：数据准备
包括下载数据集、进行数据预处理以及构建数据加载器。
第二阶段：模型准备
涵盖模型初始化、加载预训练权重、调整模型结构，并实现评估工具。
第三阶段：模型微调与部署
包括执行模型微调、评估微调效果，以及在新数据上进行推理。
在语言模型微调中，主要分为分类微调和指令微调两种类型。分类微调相对简单，例如在垃圾消息检测任务中，模型只需输出&#34;垃圾消息&#34;或&#34;非垃圾消息&#34;两类结果，适用于对分类精度要求较高的场景。本章重点在于通过调整模型结构来实现微调，因此可以重点关注模型结构的修改方法。
第一阶段：准备数据 1. 下载数据 网上有公开的垃圾邮件和非垃圾邮件数据集可供下载。
2. 数据集预处理 预处理时主要需要注意设置max_length进行截断和填充。另外，在分类任务中需要特别关注各类别数据的均衡性。
from uu import encode import torch from torch.utils.data import Dataset import tiktoken import pandas as pd class SpamDataset(Dataset): def __init__(self, csv_file, tokenizer, max_len=200,pad_token_id=50256): self.csv_file = csv_file self.data = pd.read_csv(csv_file, sep='\\t') self.encoded_texts =[tokenizer.encode(text) for text in self.data['text']] self.max_len = max_len if self.max_len: processed_texts = [] for encoded in self.encoded_texts: # 截断到最大长度 truncated = encoded[:self.max_len] # 填充到最大长度 padded = truncated + [pad_token_id] * (self.max_len - len(truncated)) processed_texts.append(padded) self.encoded_texts = processed_texts def __getitem__(self, index): encoded = self.encoded_texts[index] label = self.data.iloc[index]['label'] return (torch.tensor(encoded, dtype=torch.long), torch.tensor(label, dtype=torch.long)) def __len__(self): return len(self.data) 3. 创建数据加载器 train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_worker) val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_worker) test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_worker) 第二阶段：修改模型 1. 模型初始化 GPTModel是在《徒手组装GPT》章节中构建好的类。"><meta itemprop=datePublished content="2025-11-05T13:54:46+00:00"><meta itemprop=dateModified content="2025-11-05T13:54:46+00:00"><meta itemprop=wordCount content="571"><meta itemprop=keywords content="Tech"><meta name=lang content="chs"></head><body class="dark:bg-gray-800 dark:text-white relative flex flex-col min-h-screen"><header class="container flex justify-between md:justify-between gap-4 flex-wrap p-6 mx-auto relative"><a href=https://huizhixu.github.io/chs/ class="capitalize font-extrabold text-2xl"><img src=../../../blist-logo.png alt=徐慧志的个人博客 class="h-8 max-w-full">
</a><button class="mobile-menu-button md:hidden">
<svg width="30" height="30" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><line x1="4" y1="8" x2="20" y2="8"/><line x1="4" y1="16" x2="20" y2="16"/></svg></button><ul class="mobile-menu absolute z-10 px-6 pb-6 md:p-0 top-full left-0 w-full md:w-auto md:relative hidden md:flex flex-col md:flex-row items-end md:items-center gap-4 lg:gap-6 bg-white dark:bg-gray-800"><li><a href=../../../chs/know_how/>技术</a></li><li><a href=../../../chs/life/>生活见闻</a></li><li><a href=../../../chs/page/about/>关于</a></li><li><a href=../../../chs/link/>宝藏集结</a></li><li><a href=../../../chs/tags/>分类</a></li><li class="relative cursor-pointer"><span class="language-switcher flex items-center gap-2"><svg width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="12" cy="12" r="9"/><line x1="3.6" y1="9" x2="20.4" y2="9"/><line x1="3.6" y1="15" x2="20.4" y2="15"/><path d="M11.5 3a17 17 0 000 18"/><path d="M12.5 3a17 17 0 010 18"/></svg>
<a>语言</a>
<svg width="14" height="14" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M18 15l-6-6-6 6h12" transform="rotate(180 12 12)"/></svg></span><div class="language-dropdown absolute top-full mt-2 left-0 flex-col gap-2 bg-gray-100 dark:bg-gray-900 dark:text-white z-10 hidden"><a class="px-3 py-2 hover:bg-gray-200 dark:hover:bg-gray-700" href=../../../en/ lang=en>English</a>
<a class="px-3 py-2 hover:bg-gray-200 dark:hover:bg-gray-700" href=../../../de/ lang=de>Deutsch</a></div></li><li class="grid place-items-center"><span class="open-search inline-block cursor-pointer"><svg width="20" height="20" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg></span></li><li class="grid place-items-center"><span class="toggle-dark-mode inline-block cursor-pointer"><svg width="24" height="24" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="12" cy="12" r="3"/><line x1="12" y1="5" x2="12" y2="5.01"/><line x1="17" y1="7" x2="17" y2="7.01"/><line x1="19" y1="12" x2="19" y2="12.01"/><line x1="17" y1="17" x2="17" y2="17.01"/><line x1="12" y1="19" x2="12" y2="19.01"/><line x1="7" y1="17" x2="7" y2="17.01"/><line x1="5" y1="12" x2="5" y2="12.01"/><line x1="7" y1="7" x2="7" y2="7.01"/></svg></span></li></ul></header><main class=flex-1><article class="prose lg:prose-lg mx-auto my-8 dark:prose-dark px-4"><h1 class="text-2xl font-bold mb-2">2025-11-05 从零构建大模型—针对分类的微调</h1><h5 class="text-sm flex items-center flex-wrap"><svg class="mr-1" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><rect x="4" y="5" width="16" height="16" rx="2"/><line x1="16" y1="3" x2="16" y2="7"/><line x1="8" y1="3" x2="8" y2="7"/><line x1="4" y1="11" x2="20" y2="11"/><rect x="8" y="15" width="2" height="2"/></svg>
发布于
2025年11月05日
&nbsp;&bull;&nbsp;
<svg class="mr-1" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
3&nbsp;分钟
&nbsp;&bull;
<svg class="mx-1" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M3 19a9 9 0 019 0 9 9 0 019 0"/><path d="M3 6a9 9 0 019 0 9 9 0 019 0"/><line x1="3" y1="6" x2="3" y2="19"/><line x1="12" y1="6" x2="12" y2="19"/><line x1="21" y1="6" x2="21" y2="19"/></svg>
571&nbsp;字</h5><details id=TableOfContents class="px-4 mt-4 bg-gray-100 dark:bg-gray-700 rounded toc"><summary class="flex items-center font-bold py-2 px-4 cursor-pointer justify-between select-none text-black dark:text-white"><span>Table of contents</span>
<svg class="icon icon-tabler icon-tabler-chevron-down" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><polyline points="6 9 12 15 18 9"/></svg></summary><ul class="mt-2 pb-4"><li><a href=#%e7%ac%ac%e4%b8%80%e9%98%b6%e6%ae%b5%e5%87%86%e5%a4%87%e6%95%b0%e6%8d%ae>第一阶段：准备数据</a><ul><li><a href=#1-%e4%b8%8b%e8%bd%bd%e6%95%b0%e6%8d%ae>1. 下载数据</a></li><li><a href=#2-%e6%95%b0%e6%8d%ae%e9%9b%86%e9%a2%84%e5%a4%84%e7%90%86>2. 数据集预处理</a></li><li><a href=#3-%e5%88%9b%e5%bb%ba%e6%95%b0%e6%8d%ae%e5%8a%a0%e8%bd%bd%e5%99%a8>3. 创建数据加载器</a></li></ul></li><li><a href=#%e7%ac%ac%e4%ba%8c%e9%98%b6%e6%ae%b5%e4%bf%ae%e6%94%b9%e6%a8%a1%e5%9e%8b>第二阶段：修改模型</a><ul><li><a href=#1-%e6%a8%a1%e5%9e%8b%e5%88%9d%e5%a7%8b%e5%8c%96>1. 模型初始化</a></li><li><a href=#2-%e5%8a%a0%e8%bd%bd%e9%a2%84%e8%ae%ad%e7%bb%83%e6%9d%83%e9%87%8d>2. 加载预训练权重</a></li><li><a href=#3-%e4%bf%ae%e6%94%b9%e6%a8%a1%e5%9e%8b%e7%bb%93%e6%9e%84>3. 修改模型结构</a></li><li><a href=#4-%e5%ae%9e%e7%8e%b0%e8%af%84%e4%bc%b0%e5%b7%a5%e5%85%b7>4. 实现评估工具</a></li></ul></li><li><a href=#%e7%ac%ac%e4%b8%89%e9%98%b6%e6%ae%b5%e5%be%ae%e8%b0%83%e6%a8%a1%e5%9e%8b>第三阶段：微调模型</a><ul><li><a href=#1-%e8%ae%ad%e7%bb%83%e4%bb%a3%e7%a0%81%e5%ae%9e%e7%8e%b0>1. 训练代码实现</a></li><li><a href=#2-%e8%af%84%e4%bc%b0%e5%be%ae%e8%b0%83%e5%90%8e%e7%9a%84%e6%a8%a1%e5%9e%8b>2. 评估微调后的模型</a></li><li><a href=#3-%e5%9c%a8%e6%96%b0%e6%95%b0%e6%8d%ae%e4%b8%8a%e4%bd%bf%e7%94%a8%e6%a8%a1%e5%9e%8b%e8%bf%9b%e8%a1%8c%e6%8e%a8%e7%90%86>3. 在新数据上使用模型进行推理</a></li></ul></li></ul></details><p>这本书最后两章的例子9月底就运行完了，但是微信读书会员到期了。最近又开了会员复习了一遍，记录下来。</p><p>微调通常可分为以下三个阶段：</p><p>第一阶段：数据准备</p><p>包括下载数据集、进行数据预处理以及构建数据加载器。</p><p>第二阶段：模型准备</p><p>涵盖模型初始化、加载预训练权重、调整模型结构，并实现评估工具。</p><p>第三阶段：模型微调与部署</p><p>包括执行模型微调、评估微调效果，以及在新数据上进行推理。</p><p>在语言模型微调中，主要分为分类微调和指令微调两种类型。分类微调相对简单，例如在垃圾消息检测任务中，模型只需输出"垃圾消息"或"非垃圾消息"两类结果，适用于对分类精度要求较高的场景。本章重点在于通过调整模型结构来实现微调，因此可以重点关注模型结构的修改方法。</p><h2 id=第一阶段准备数据>第一阶段：准备数据</h2><h3 id=1-下载数据>1. 下载数据</h3><p>网上有公开的垃圾邮件和非垃圾邮件数据集可供下载。</p><h3 id=2-数据集预处理>2. 数据集预处理</h3><p>预处理时主要需要注意设置max_length进行截断和填充。另外，在分类任务中需要特别关注各类别数据的均衡性。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>from</span> uu <span style=color:#ff79c6>import</span> encode
</span></span><span style=display:flex><span><span style=color:#ff79c6>import</span> torch
</span></span><span style=display:flex><span><span style=color:#ff79c6>from</span> torch.utils.data <span style=color:#ff79c6>import</span> Dataset
</span></span><span style=display:flex><span><span style=color:#ff79c6>import</span> tiktoken
</span></span><span style=display:flex><span><span style=color:#ff79c6>import</span> pandas <span style=color:#ff79c6>as</span> pd
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>class</span> <span style=color:#50fa7b>SpamDataset</span>(Dataset):
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>def</span> <span style=color:#50fa7b>__init__</span>(<span style=font-style:italic>self</span>, csv_file, tokenizer, max_len<span style=color:#ff79c6>=</span><span style=color:#bd93f9>200</span>,pad_token_id<span style=color:#ff79c6>=</span><span style=color:#bd93f9>50256</span>):
</span></span><span style=display:flex><span>        <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>csv_file <span style=color:#ff79c6>=</span> csv_file
</span></span><span style=display:flex><span>        <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>data <span style=color:#ff79c6>=</span> pd<span style=color:#ff79c6>.</span>read_csv(csv_file, sep<span style=color:#ff79c6>=</span><span style=color:#f1fa8c>&#39;</span><span style=color:#f1fa8c>\\</span><span style=color:#f1fa8c>t&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>encoded_texts <span style=color:#ff79c6>=</span>[tokenizer<span style=color:#ff79c6>.</span>encode(text) <span style=color:#ff79c6>for</span> text <span style=color:#ff79c6>in</span> <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>data[<span style=color:#f1fa8c>&#39;text&#39;</span>]]
</span></span><span style=display:flex><span>        <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>max_len <span style=color:#ff79c6>=</span> max_len
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>if</span> <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>max_len:
</span></span><span style=display:flex><span>            processed_texts <span style=color:#ff79c6>=</span> []
</span></span><span style=display:flex><span>            <span style=color:#ff79c6>for</span> encoded <span style=color:#ff79c6>in</span> <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>encoded_texts:
</span></span><span style=display:flex><span>                <span style=color:#6272a4># 截断到最大长度</span>
</span></span><span style=display:flex><span>                truncated <span style=color:#ff79c6>=</span> encoded[:<span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>max_len]
</span></span><span style=display:flex><span>                <span style=color:#6272a4># 填充到最大长度</span>
</span></span><span style=display:flex><span>                padded <span style=color:#ff79c6>=</span> truncated <span style=color:#ff79c6>+</span> [pad_token_id] <span style=color:#ff79c6>*</span> (<span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>max_len <span style=color:#ff79c6>-</span> <span style=color:#8be9fd;font-style:italic>len</span>(truncated))
</span></span><span style=display:flex><span>                processed_texts<span style=color:#ff79c6>.</span>append(padded)
</span></span><span style=display:flex><span>            <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>encoded_texts <span style=color:#ff79c6>=</span> processed_texts
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>def</span> <span style=color:#50fa7b>__getitem__</span>(<span style=font-style:italic>self</span>, index):
</span></span><span style=display:flex><span>        encoded <span style=color:#ff79c6>=</span> <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>encoded_texts[index]
</span></span><span style=display:flex><span>        label <span style=color:#ff79c6>=</span> <span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>data<span style=color:#ff79c6>.</span>iloc[index][<span style=color:#f1fa8c>&#39;label&#39;</span>]
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>return</span> (torch<span style=color:#ff79c6>.</span>tensor(encoded, dtype<span style=color:#ff79c6>=</span>torch<span style=color:#ff79c6>.</span>long), torch<span style=color:#ff79c6>.</span>tensor(label, dtype<span style=color:#ff79c6>=</span>torch<span style=color:#ff79c6>.</span>long))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>def</span> <span style=color:#50fa7b>__len__</span>(<span style=font-style:italic>self</span>):
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>return</span> <span style=color:#8be9fd;font-style:italic>len</span>(<span style=font-style:italic>self</span><span style=color:#ff79c6>.</span>data)
</span></span></code></pre></div><h3 id=3-创建数据加载器>3. 创建数据加载器</h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>train_loader <span style=color:#ff79c6>=</span> DataLoader(train_dataset, batch_size<span style=color:#ff79c6>=</span>batch_size, shuffle<span style=color:#ff79c6>=</span><span style=color:#ff79c6>True</span>, num_workers<span style=color:#ff79c6>=</span>num_worker)
</span></span><span style=display:flex><span>val_loader <span style=color:#ff79c6>=</span> DataLoader(val_dataset, batch_size<span style=color:#ff79c6>=</span>batch_size, shuffle<span style=color:#ff79c6>=</span><span style=color:#ff79c6>False</span>, num_workers<span style=color:#ff79c6>=</span>num_worker)
</span></span><span style=display:flex><span>test_loader <span style=color:#ff79c6>=</span> DataLoader(test_dataset, batch_size<span style=color:#ff79c6>=</span>batch_size, shuffle<span style=color:#ff79c6>=</span><span style=color:#ff79c6>False</span>, num_workers<span style=color:#ff79c6>=</span>num_worker)
</span></span></code></pre></div><h2 id=第二阶段修改模型>第二阶段：修改模型</h2><h3 id=1-模型初始化>1. 模型初始化</h3><p>GPTModel是在《徒手组装GPT》章节中构建好的类。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>BASE_CONFIG  <span style=color:#ff79c6>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#f1fa8c>&#34;vocab_size&#34;</span>: <span style=color:#bd93f9>50257</span>,
</span></span><span style=display:flex><span>    <span style=color:#f1fa8c>&#34;context_length&#34;</span>: <span style=color:#bd93f9>1024</span>,
</span></span><span style=display:flex><span>    <span style=color:#f1fa8c>&#34;drop_rate&#34;</span>: <span style=color:#bd93f9>0.0</span>,
</span></span><span style=display:flex><span>    <span style=color:#f1fa8c>&#34;qkv_bias&#34;</span>: <span style=color:#ff79c6>True</span>
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>models_config <span style=color:#ff79c6>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#f1fa8c>&#34;gpt2&#34;</span>: {<span style=color:#f1fa8c>&#34;emb_dim&#34;</span>:<span style=color:#bd93f9>768</span>,<span style=color:#f1fa8c>&#34;n_heads&#34;</span>:<span style=color:#bd93f9>12</span>, <span style=color:#f1fa8c>&#34;n_layers&#34;</span>:<span style=color:#bd93f9>12</span>,},
</span></span><span style=display:flex><span>    <span style=color:#f1fa8c>&#34;gpt2-medium&#34;</span>: {<span style=color:#f1fa8c>&#34;emb_dim&#34;</span>:<span style=color:#bd93f9>1024</span>,<span style=color:#f1fa8c>&#34;n_heads&#34;</span>:<span style=color:#bd93f9>16</span>, <span style=color:#f1fa8c>&#34;n_layers&#34;</span>:<span style=color:#bd93f9>24</span>,},
</span></span><span style=display:flex><span>    <span style=color:#f1fa8c>&#34;gpt2-large&#34;</span>: {<span style=color:#f1fa8c>&#34;emb_dim&#34;</span>:<span style=color:#bd93f9>1280</span>,<span style=color:#f1fa8c>&#34;n_heads&#34;</span>:<span style=color:#bd93f9>20</span>, <span style=color:#f1fa8c>&#34;n_layers&#34;</span>:<span style=color:#bd93f9>36</span>,},
</span></span><span style=display:flex><span>    <span style=color:#f1fa8c>&#34;gpt2-xl&#34;</span>: {<span style=color:#f1fa8c>&#34;emb_dim&#34;</span>:<span style=color:#bd93f9>1600</span>,<span style=color:#f1fa8c>&#34;n_heads&#34;</span>:<span style=color:#bd93f9>25</span>, <span style=color:#f1fa8c>&#34;n_layers&#34;</span>:<span style=color:#bd93f9>48</span>,},
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>CHOOSE_MODEL<span style=color:#ff79c6>=</span> <span style=color:#f1fa8c>&#34;gpt2-xl&#34;</span>
</span></span><span style=display:flex><span>BASE_CONFIG<span style=color:#ff79c6>.</span>update(models_config[CHOOSE_MODEL])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model_size <span style=color:#ff79c6>=</span> CHOOSE_MODEL<span style=color:#ff79c6>.</span>split(<span style=color:#f1fa8c>&#34; &#34;</span>)[<span style=color:#ff79c6>-</span><span style=color:#bd93f9>1</span>]<span style=color:#ff79c6>.</span>lstrip(<span style=color:#f1fa8c>&#34;(&#34;</span>)<span style=color:#ff79c6>.</span>rstrip(<span style=color:#f1fa8c>&#34;)&#34;</span>)
</span></span><span style=display:flex><span>model <span style=color:#ff79c6>=</span> GPTModel(BASE_CONFIG)
</span></span></code></pre></div><h3 id=2-加载预训练权重>2. 加载预训练权重</h3><p>这里也是之前的章节写过的。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>params <span style=color:#ff79c6>=</span> build_openai_numpy_dict(CHOOSE_MODEL)
</span></span><span style=display:flex><span>load_weights_into_gpt(model, params)
</span></span><span style=display:flex><span>model<span style=color:#ff79c6>.</span>eval()
</span></span></code></pre></div><h3 id=3-修改模型结构>3. 修改模型结构</h3><p>这是本章最重要的部分。</p><p>第一步：确定微调策略
需要考虑是微调选定层还是微调所有层。在基于神经网络的语言模型中，较低层通常捕捉基本的语言结构和语义，适用于广泛的任务和数据集，而最后几层（靠近输出的层）更侧重于捕捉细微的语言模式和特定任务的特征。因此，通常选择微调靠近输出层的少数层。</p><p>第二步：修改输出层
原始输出层的输出维度是词汇表大小（50257），现在要进行二分类，需要将输出节点的数量与类别数量相匹配。</p><p>GPTModel的结构如下：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>GPTModel(
</span></span><span style=display:flex><span>  (tok_emb): Embedding(<span style=color:#bd93f9>50257</span>, <span style=color:#bd93f9>768</span>)
</span></span><span style=display:flex><span>  (pos_emb): Embedding(<span style=color:#bd93f9>1024</span>, <span style=color:#bd93f9>768</span>)
</span></span><span style=display:flex><span>  (drop_emb): Dropout(p<span style=color:#ff79c6>=</span><span style=color:#bd93f9>0.0</span>, inplace<span style=color:#ff79c6>=</span><span style=color:#ff79c6>False</span>)
</span></span><span style=display:flex><span>  (trf_blocks): Sequential(
</span></span><span style=display:flex><span><span style=color:#ff79c6>...</span>
</span></span><span style=display:flex><span>    (<span style=color:#bd93f9>11</span>): TransformerBlock(
</span></span><span style=display:flex><span>      (att): MultiHeadAttention(
</span></span><span style=display:flex><span>        (W_query): Linear(in_features<span style=color:#ff79c6>=</span><span style=color:#bd93f9>768</span>, out_features<span style=color:#ff79c6>=</span><span style=color:#bd93f9>768</span>, bias<span style=color:#ff79c6>=</span><span style=color:#ff79c6>True</span>)
</span></span><span style=display:flex><span>        (W_key): Linear(in_features<span style=color:#ff79c6>=</span><span style=color:#bd93f9>768</span>, out_features<span style=color:#ff79c6>=</span><span style=color:#bd93f9>768</span>, bias<span style=color:#ff79c6>=</span><span style=color:#ff79c6>True</span>)
</span></span><span style=display:flex><span>        (W_value): Linear(in_features<span style=color:#ff79c6>=</span><span style=color:#bd93f9>768</span>, out_features<span style=color:#ff79c6>=</span><span style=color:#bd93f9>768</span>, bias<span style=color:#ff79c6>=</span><span style=color:#ff79c6>True</span>)
</span></span><span style=display:flex><span>        (out_proj): Linear(in_features<span style=color:#ff79c6>=</span><span style=color:#bd93f9>768</span>, out_features<span style=color:#ff79c6>=</span><span style=color:#bd93f9>768</span>, bias<span style=color:#ff79c6>=</span><span style=color:#ff79c6>True</span>)
</span></span><span style=display:flex><span>        (dropout): Dropout(p<span style=color:#ff79c6>=</span><span style=color:#bd93f9>0.0</span>, inplace<span style=color:#ff79c6>=</span><span style=color:#ff79c6>False</span>)
</span></span><span style=display:flex><span>      )
</span></span><span style=display:flex><span>      (ff): FeedForward(
</span></span><span style=display:flex><span>        (layers): Sequential(
</span></span><span style=display:flex><span>          (<span style=color:#bd93f9>0</span>): Linear(in_features<span style=color:#ff79c6>=</span><span style=color:#bd93f9>768</span>, out_features<span style=color:#ff79c6>=</span><span style=color:#bd93f9>3072</span>, bias<span style=color:#ff79c6>=</span><span style=color:#ff79c6>True</span>)
</span></span><span style=display:flex><span>          (<span style=color:#bd93f9>1</span>): GELU()
</span></span><span style=display:flex><span>          (<span style=color:#bd93f9>2</span>): Linear(in_features<span style=color:#ff79c6>=</span><span style=color:#bd93f9>3072</span>, out_features<span style=color:#ff79c6>=</span><span style=color:#bd93f9>768</span>, bias<span style=color:#ff79c6>=</span><span style=color:#ff79c6>True</span>)
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>      )
</span></span><span style=display:flex><span>      (norm1): LayerNorm()
</span></span><span style=display:flex><span>      (norm2): LayerNorm()
</span></span><span style=display:flex><span>      (drop_resid): Dropout(p<span style=color:#ff79c6>=</span><span style=color:#bd93f9>0.0</span>, inplace<span style=color:#ff79c6>=</span><span style=color:#ff79c6>False</span>)
</span></span><span style=display:flex><span>    )
</span></span><span style=display:flex><span>  )
</span></span><span style=display:flex><span>  (final_norm): LayerNorm()
</span></span><span style=display:flex><span>  (out_head): Linear(in_features<span style=color:#ff79c6>=</span><span style=color:#bd93f9>768</span>, out_features<span style=color:#ff79c6>=</span><span style=color:#bd93f9>50257</span>, bias<span style=color:#ff79c6>=</span><span style=color:#ff79c6>False</span>)
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><p>这里需要将out_head替换为新的输出层，并对其进行微调。</p><p>具体操作：</p><p>首先冻结模型，将所有层设为不可训练：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>for</span> param <span style=color:#ff79c6>in</span> model<span style=color:#ff79c6>.</span>parameters():
</span></span><span style=display:flex><span>    param<span style=color:#ff79c6>.</span>requires_grad <span style=color:#ff79c6>=</span> <span style=color:#ff79c6>False</span>
</span></span></code></pre></div><p>然后添加分类层（新添加的输出层的requires_grad属性默认设置为True）：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>torch<span style=color:#ff79c6>.</span>manual_seed(<span style=color:#bd93f9>123</span>)
</span></span><span style=display:flex><span>num_classes <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>2</span>
</span></span><span style=display:flex><span>model<span style=color:#ff79c6>.</span>out_head <span style=color:#ff79c6>=</span> torch<span style=color:#ff79c6>.</span>nn<span style=color:#ff79c6>.</span>Linear(
</span></span><span style=display:flex><span>    in_features<span style=color:#ff79c6>=</span>BASE_CONFIG[<span style=color:#f1fa8c>&#34;emb_dim&#34;</span>],
</span></span><span style=display:flex><span>    out_features<span style=color:#ff79c6>=</span>num_classes
</span></span><span style=display:flex><span>)
</span></span></code></pre></div><p>最后添加少量其他层参与微调，将最后一个Transformer块和连接该块到输出层的最终层归一化模块设置为可训练：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>for</span> param <span style=color:#ff79c6>in</span> model<span style=color:#ff79c6>.</span>trf_blocks[<span style=color:#ff79c6>-</span><span style=color:#bd93f9>1</span>]<span style=color:#ff79c6>.</span>parameters():
</span></span><span style=display:flex><span>    param<span style=color:#ff79c6>.</span>requires_grad <span style=color:#ff79c6>=</span> <span style=color:#ff79c6>True</span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>for</span> param <span style=color:#ff79c6>in</span> model<span style=color:#ff79c6>.</span>final_norm<span style=color:#ff79c6>.</span>parameters():
</span></span><span style=display:flex><span>    param<span style=color:#ff79c6>.</span>requires_grad <span style=color:#ff79c6>=</span> <span style=color:#ff79c6>True</span>
</span></span></code></pre></div><h3 id=4-实现评估工具>4. 实现评估工具</h3><p>我们的目标是最大化模型的垃圾消息分类准确率，因此需要定义训练期间要优化的损失函数。</p><p>这里需要实现两个功能：计算分类准确率和计算分类损失。</p><p>计算分类准确率：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>def</span> <span style=color:#50fa7b>calc_accuracy_loader</span>(data_loader, model, device, num_batches<span style=color:#ff79c6>=</span><span style=color:#ff79c6>None</span>):
</span></span><span style=display:flex><span>    model<span style=color:#ff79c6>.</span>eval()
</span></span><span style=display:flex><span>    correct_predictions, num_examples <span style=color:#ff79c6>=</span><span style=color:#bd93f9>0</span>,<span style=color:#bd93f9>0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>if</span> num_batches <span style=color:#ff79c6>is</span> <span style=color:#ff79c6>None</span>:
</span></span><span style=display:flex><span>        num_batches <span style=color:#ff79c6>=</span><span style=color:#8be9fd;font-style:italic>len</span>(data_loader)
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>else</span>:
</span></span><span style=display:flex><span>        num_batches <span style=color:#ff79c6>=</span> <span style=color:#8be9fd;font-style:italic>min</span>(num_batches, <span style=color:#8be9fd;font-style:italic>len</span>(data_loader))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>for</span> i, (input_batch, target_batch) <span style=color:#ff79c6>in</span> <span style=color:#8be9fd;font-style:italic>enumerate</span>(data_loader):
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>if</span> i <span style=color:#ff79c6>&lt;</span> num_batches:
</span></span><span style=display:flex><span>            input_batch <span style=color:#ff79c6>=</span>input_batch<span style=color:#ff79c6>.</span>to(device)
</span></span><span style=display:flex><span>            target_batch <span style=color:#ff79c6>=</span>target_batch<span style=color:#ff79c6>.</span>to(device)
</span></span><span style=display:flex><span>            <span style=color:#ff79c6>with</span> torch<span style=color:#ff79c6>.</span>no_grad():
</span></span><span style=display:flex><span>                logits <span style=color:#ff79c6>=</span> model(input_batch)
</span></span><span style=display:flex><span>                logits <span style=color:#ff79c6>=</span> logits[:, <span style=color:#ff79c6>-</span><span style=color:#bd93f9>1</span>, :]        <span style=color:#6272a4># (B, 2)</span>
</span></span><span style=display:flex><span>            predicted_label <span style=color:#ff79c6>=</span> torch<span style=color:#ff79c6>.</span>argmax(logits, dim<span style=color:#ff79c6>=-</span><span style=color:#bd93f9>1</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>            num_examples <span style=color:#ff79c6>+=</span> predicted_label<span style=color:#ff79c6>.</span>shape[<span style=color:#bd93f9>0</span>]
</span></span><span style=display:flex><span>            correct_predictions <span style=color:#ff79c6>+=</span> (predicted_label <span style=color:#ff79c6>==</span> target_batch)<span style=color:#ff79c6>.</span>sum()<span style=color:#ff79c6>.</span>item()
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>else</span>:
</span></span><span style=display:flex><span>            <span style=color:#ff79c6>break</span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>return</span> correct_predictions <span style=color:#ff79c6>/</span> num_examples
</span></span></code></pre></div><p>GPT2模型通过softmax函数将50257个输出转换为概率，然后利用argmax函数返回最高概率的位置，来计算大语言模型生成的下一个词元的词元ID。</p><p>代码中分类模型也是通过查找最高概率分数的索引位置获得类别标签：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>logits <span style=color:#ff79c6>=</span> outputs[:, <span style=color:#ff79c6>-</span><span style=color:#bd93f9>1</span>, :]
</span></span><span style=display:flex><span>label <span style=color:#ff79c6>=</span> torch<span style=color:#ff79c6>.</span>argmax(logits)
</span></span><span style=display:flex><span><span style=color:#8be9fd;font-style:italic>print</span>(<span style=color:#f1fa8c>&#34;Class label:&#34;</span>, label<span style=color:#ff79c6>.</span>item())
</span></span></code></pre></div><p>计算损失函数：
使用交叉熵损失作为替代来最大化准确率。这里要注意的是优化最后一个词元而不是所有词元：logits = model(input_batch)[:, -1, :]。</p><p>为什么只需要关注最后一个输出词元？</p><p>如果输入n个词元，输出也会是n个词元。按照因果注意力掩码机制，每个词元只能关注当前及之前的位置，从而确保每个词元只受自己和之前词元的影响。因此，最后一个词元能够知晓之前所有数据的信息，所以我们重点关注最后一个输出词元。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>def</span> <span style=color:#50fa7b>calc_loss_batch</span>(input_batch, output_batch, model, device):
</span></span><span style=display:flex><span>    input_batch <span style=color:#ff79c6>=</span> input_batch<span style=color:#ff79c6>.</span>to(device)
</span></span><span style=display:flex><span>    output_batch <span style=color:#ff79c6>=</span> output_batch<span style=color:#ff79c6>.</span>to(device)
</span></span><span style=display:flex><span>    logits <span style=color:#ff79c6>=</span> model(input_batch)[:, <span style=color:#ff79c6>-</span><span style=color:#bd93f9>1</span>, :]
</span></span><span style=display:flex><span>    loss <span style=color:#ff79c6>=</span> torch<span style=color:#ff79c6>.</span>nn<span style=color:#ff79c6>.</span>functional<span style=color:#ff79c6>.</span>cross_entropy(logits, output_batch)
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>return</span> loss
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>def</span> <span style=color:#50fa7b>calc_loss_loader</span>(data_loader, model, device, num_batches<span style=color:#ff79c6>=</span><span style=color:#ff79c6>None</span>):
</span></span><span style=display:flex><span>    total_loss <span style=color:#ff79c6>=</span><span style=color:#bd93f9>0.0</span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>if</span> <span style=color:#8be9fd;font-style:italic>len</span>(data_loader) <span style=color:#ff79c6>==</span> <span style=color:#bd93f9>0</span>:
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>return</span> <span style=color:#8be9fd;font-style:italic>float</span>(<span style=color:#f1fa8c>&#34;nan&#34;</span>)
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>elif</span> num_batches <span style=color:#ff79c6>is</span> <span style=color:#ff79c6>None</span>:
</span></span><span style=display:flex><span>        num_batches <span style=color:#ff79c6>=</span><span style=color:#8be9fd;font-style:italic>len</span>(data_loader)
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>else</span>:
</span></span><span style=display:flex><span>        num_batches <span style=color:#ff79c6>=</span> <span style=color:#8be9fd;font-style:italic>min</span>(num_batches, <span style=color:#8be9fd;font-style:italic>len</span>(data_loader))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>for</span> i, (input_batch, target_batch) <span style=color:#ff79c6>in</span> <span style=color:#8be9fd;font-style:italic>enumerate</span>(data_loader):
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>if</span> i <span style=color:#ff79c6>&lt;</span> num_batches:
</span></span><span style=display:flex><span>            loss <span style=color:#ff79c6>=</span> calc_loss_batch(input_batch, target_batch, model, device)
</span></span><span style=display:flex><span>            total_loss <span style=color:#ff79c6>+=</span> loss<span style=color:#ff79c6>.</span>item()
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>else</span>:
</span></span><span style=display:flex><span>            <span style=color:#ff79c6>break</span>
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>return</span> total_loss <span style=color:#ff79c6>/</span> num_batches
</span></span></code></pre></div><h2 id=第三阶段微调模型>第三阶段：微调模型</h2><h3 id=1-训练代码实现>1. 训练代码实现</h3><p>在每次循环中，我们计算每个训练集批次的损失以确定损失梯度，然后使用这些梯度来更新模型权重，以便训练集损失最小化。</p><p>训练步骤：</p><ol><li>遍历训练轮次（一轮就是完整地遍历一次训练集）</li><li>在每个训练轮次中遍历批次（批次数量由训练集大小除以每个批次的大小确定）</li><li>从上一个批次迭代中重置损失函数</li><li>计算当前批次的损失</li><li>反向传播以计算损失梯度</li><li>使用损失梯度更新模型权重</li><li>打印训练集和验证集的损失（可选）
训练代码：</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#ff79c6>for</span> epoch <span style=color:#ff79c6>in</span> <span style=color:#8be9fd;font-style:italic>range</span>(num_epochs): <span style=color:#6272a4># step 1</span>
</span></span><span style=display:flex><span>        epoch_loss <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>0.0</span>
</span></span><span style=display:flex><span>        epoch_batches <span style=color:#ff79c6>=</span> <span style=color:#bd93f9>0</span>
</span></span><span style=display:flex><span>        model<span style=color:#ff79c6>.</span>train()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#ff79c6>for</span> input_batch, output_batch <span style=color:#ff79c6>in</span> train_loader:  <span style=color:#6272a4># step 2</span>
</span></span><span style=display:flex><span>            optimizer<span style=color:#ff79c6>.</span>zero_grad() <span style=color:#6272a4># step 3</span>
</span></span><span style=display:flex><span>            loss <span style=color:#ff79c6>=</span> calc_loss_batch(input_batch, output_batch, model, device) <span style=color:#6272a4># step 4</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>            loss<span style=color:#ff79c6>.</span>backward()<span style=color:#6272a4># step 5</span>
</span></span><span style=display:flex><span>            optimizer<span style=color:#ff79c6>.</span>step() <span style=color:#6272a4># step 6</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>            global_step <span style=color:#ff79c6>+=</span> <span style=color:#bd93f9>1</span>
</span></span><span style=display:flex><span>            epoch_loss  <span style=color:#ff79c6>+=</span> loss<span style=color:#ff79c6>.</span>item()
</span></span><span style=display:flex><span>            epoch_batches <span style=color:#ff79c6>+=</span> <span style=color:#bd93f9>1</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>            <span style=color:#ff79c6>if</span> global_step <span style=color:#ff79c6>%</span> eval_freq <span style=color:#ff79c6>==</span><span style=color:#bd93f9>0</span>:
</span></span><span style=display:flex><span>                train_loss, val_loss <span style=color:#ff79c6>=</span> evaluate_model(
</span></span><span style=display:flex><span>                    model, train_loader, val_loader, device, eval_iter
</span></span><span style=display:flex><span>                )
</span></span><span style=display:flex><span>                train_osses<span style=color:#ff79c6>.</span>append(train_loss)
</span></span><span style=display:flex><span>                val_losses<span style=color:#ff79c6>.</span>append(val_loss)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ff79c6>def</span> <span style=color:#50fa7b>evaluate_model</span>(model, train_loader, val_loader, device, eval_iter):
</span></span><span style=display:flex><span>    model<span style=color:#ff79c6>.</span>eval()
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>with</span> torch<span style=color:#ff79c6>.</span>no_grad():
</span></span><span style=display:flex><span>        train_loss <span style=color:#ff79c6>=</span> calc_loss_loader(
</span></span><span style=display:flex><span>            train_loader, model, device, num_batches<span style=color:#ff79c6>=</span>eval_iter
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>        val_loss <span style=color:#ff79c6>=</span> calc_loss_loader(
</span></span><span style=display:flex><span>            val_loader, model, device, num_batches<span style=color:#ff79c6>=</span>eval_iter
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>    model<span style=color:#ff79c6>.</span>train()
</span></span><span style=display:flex><span>    <span style=color:#ff79c6>return</span> train_loss, val_loss
</span></span></code></pre></div><p>训练过程中的关键问题：</p><ul><li>如何选择训练轮数？
通常情况下，5轮是一个不错的起点。如果模型在前几轮之后出现过拟合，则可能需要减少轮数。相反，如果趋势表明验证集损失可能随着进一步训练而改善，则应该增加轮数。</li><li>如何选择批次大小？
最开始一般取单卡GPU最大可塞下的batch_size的0.7倍。</li></ul><h3 id=2-评估微调后的模型>2. 评估微调后的模型</h3><p>可以通过计算损失函数值和对测试集进行推理生成来评估模型性能。</p><h3 id=3-在新数据上使用模型进行推理>3. 在新数据上使用模型进行推理</h3><p>主要是模型的保存和加载：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>torch<span style=color:#ff79c6>.</span>save(model<span style=color:#ff79c6>.</span>state_dict(), <span style=color:#f1fa8c>&#34;review_classifier.pth&#34;</span>)
</span></span></code></pre></div></article><div class="px-2 mb-2"><script src=https://utteranc.es/client.js repo=HuizhiXu/huizhixu.github.io issue-term=pathname theme=github-light crossorigin=anonymous async></script></div><div class="bg-blue-100 dark:bg-gray-900"><div class="container px-4 py-12 mx-auto max-w-4xl grid grid-cols-1 md:grid-cols-2 gap-4 items-center"><div><div class="text-2xl font-bold mb-2">Sein heißt werden, leben heißt lernen.</div><p class=opacity-60>Der einfache Weg is immer verkehrt.</p></div><ul class="flex justify-center gap-x-3 flex-wrap gap-y-2"><li><a href=https://twitter.com/ target=_blank rel=noopener aria-label=Twitter class="p-1 inline-block rounded-full border border-transparent text-gray-500 hover:text-gray-800 hover:border-gray-800 cursor-pointer transition-colors dark:text-gray-600 dark:hover:border-gray-300 dark:hover:text-gray-300"><svg width="24" height="24" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M22 4.01c-1 .49-1.98.689-3 .99-1.121-1.265-2.783-1.335-4.38-.737S11.977 6.323 12 8v1c-3.245.083-6.135-1.395-8-4 0 0-4.182 7.433 4 11-1.872 1.247-3.739 2.088-6 2 3.308 1.803 6.913 2.423 10.034 1.517 3.58-1.04 6.522-3.723 7.651-7.742a13.84 13.84.0 00.497-3.753C20.18 7.773 21.692 5.25 22 4.009z"/></svg></a></li><li><a href=https://github.com/ target=_blank rel=noopener aria-label=GitHub class="p-1 inline-block rounded-full border border-transparent text-gray-500 hover:text-gray-800 hover:border-gray-800 cursor-pointer transition-colors dark:text-gray-600 dark:hover:border-gray-300 dark:hover:text-gray-300"><svg width="24" height="24" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ul></div></div></main><footer class="container p-6 mx-auto flex justify-between items-center"><span class="text-sm font-light">Copyright © 2012 - Huizhi Xu · All rights reserved
</span><span onclick='window.scrollTo({top:0,behavior:"smooth"})' class="p-1 cursor-pointer"><svg width="30" height="30" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M18 15l-6-6-6 6h12"/></svg></span></footer><div class="search-ui absolute top-0 left-0 w-full h-full bg-white dark:bg-gray-800 hidden"><div class="container max-w-3xl mx-auto p-12"><div class=relative><div class="my-4 text-center text-2xl font-bold">Search</div><span class="p-2 absolute right-0 top-0 cursor-pointer close-search"><svg width="24" height="24" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><line x1="18" y1="6" x2="6" y2="18"/><line x1="6" y1="6" x2="18" y2="18"/></svg></span></div><input type=search class="py-2 px-3 w-full dark:text-black border dark:border-transparent" placeholder="Enter search query"><div class="search-results text-lg font-medium my-4 hidden">Results</div><ul class="search-list my-2"></ul><div class="no-results text-center my-8 hidden"><div class="text-xl font-semibold mb-2">No results found</div><p class="font-light text-sm">Try adjusting your search query</p></div></div></div><script src=https://huizhixu.github.io/js/scripts.min.js></script><script>const languageMenuButton=document.querySelector(".language-switcher"),languageDropdown=document.querySelector(".language-dropdown");languageMenuButton.addEventListener("click",e=>{e.preventDefault(),languageDropdown.classList.contains("hidden")?(languageDropdown.classList.remove("hidden"),languageDropdown.classList.add("flex")):(languageDropdown.classList.add("hidden"),languageDropdown.classList.remove("flex"))})</script><script>const darkmode=document.querySelector(".toggle-dark-mode");function toggleDarkMode(){document.documentElement.classList.contains("dark")?(document.documentElement.classList.remove("dark"),localStorage.setItem("darkmode","light")):(document.documentElement.classList.add("dark"),localStorage.setItem("darkmode","dark"))}darkmode&&darkmode.addEventListener("click",toggleDarkMode);const darkStorage=localStorage.getItem("darkmode"),isBrowserDark=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches;!darkStorage&&isBrowserDark&&document.documentElement.classList.add("dark"),darkStorage&&darkStorage==="dark"&&toggleDarkMode()</script><script>const mobileMenuButton=document.querySelector(".mobile-menu-button"),mobileMenu=document.querySelector(".mobile-menu");function toggleMenu(){mobileMenu.classList.toggle("hidden"),mobileMenu.classList.toggle("flex")}mobileMenu&&mobileMenuButton&&mobileMenuButton.addEventListener("click",toggleMenu)</script></body></html>