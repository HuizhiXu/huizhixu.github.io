<!doctype html><html lang=chs itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link rel=icon href=../../../favicon.svg><title>2025-10-01 姚顺雨博士答辩总结 Language Agents_Benchmarks, Methods and Frameworks - 徐慧志的个人博客</title><meta name=description content="不得不感叹互联网真是太好了。近期在看一些 Agent 领域的论文时，发现无论如何都绕不开ReAct这个框架——它如此简洁，却又如此有效，真正体现了“大道至简”的思想。我在YouTube上找到了ReAct的作者Yao Shunyu的博士答辩。非常感谢这种无私的分享，让我获得了一次极其宝贵的学习机会。
视频链接：https://www.youtube.com/watch?v=zwfE6J2BIR4
注：文中所有的图都来自上面视频链接，文中不再注明
概览
Agent：


Rule-based agents: manual design 人工写规则


Learning-based agents: trial-and-error 靠试错学习


Language agents: reasoning to act 先用语言推理，再行动
Environment：


Interact with humans/physical world 与人交互


Interact with games/simulation 与游戏交互


Interact with the digital world (Internet) 与互联网交互
Challenges:


Accessible methods for general agents


Scalable benchmarks for practical tasks
主要的研究：


Part 1: Benchmarking agents via digital automation


Part 2: Building language agents that reason to act


Part 3: Principled framework for language agents"><meta name=generator content="Hugo 0.152.2"><link rel=stylesheet href="/css/styles.min.cc1204abf55b2794a944c9970dcfbbedd8cddb0c0451f7d9b088371efe0b6248.css" integrity crossorigin=anonymous><meta property="og:url" content="https://huizhixu.github.io/chs/know_how/20251001-%E5%A7%9A%E9%A1%BA%E9%9B%A8%E5%8D%9A%E5%A3%AB%E7%AD%94%E8%BE%A9%E6%80%BB%E7%BB%93-language-agentsbenchmarks-methods-and-frameworks/"><meta property="og:site_name" content="徐慧志的个人博客"><meta property="og:title" content="2025-10-01 姚顺雨博士答辩总结 Language Agents_Benchmarks, Methods and Frameworks"><meta property="og:description" content="不得不感叹互联网真是太好了。近期在看一些 Agent 领域的论文时，发现无论如何都绕不开ReAct这个框架——它如此简洁，却又如此有效，真正体现了“大道至简”的思想。我在YouTube上找到了ReAct的作者Yao Shunyu的博士答辩。非常感谢这种无私的分享，让我获得了一次极其宝贵的学习机会。
视频链接：https://www.youtube.com/watch?v=zwfE6J2BIR4
注：文中所有的图都来自上面视频链接，文中不再注明
概览 Agent：
Rule-based agents: manual design 人工写规则
Learning-based agents: trial-and-error 靠试错学习
Language agents: reasoning to act 先用语言推理，再行动 Environment：
Interact with humans/physical world 与人交互
Interact with games/simulation 与游戏交互
Interact with the digital world (Internet) 与互联网交互 Challenges:
Accessible methods for general agents
Scalable benchmarks for practical tasks 主要的研究：
Part 1: Benchmarking agents via digital automation
Part 2: Building language agents that reason to act
Part 3: Principled framework for language agents"><meta property="og:locale" content="chs"><meta property="og:type" content="article"><meta property="article:section" content="know_how"><meta property="article:published_time" content="2025-10-01T14:11:50+00:00"><meta property="article:modified_time" content="2025-10-01T14:11:50+00:00"><meta property="article:tag" content="Tech"><meta name=twitter:card content="summary"><meta name=twitter:title content="2025-10-01 姚顺雨博士答辩总结 Language Agents_Benchmarks, Methods and Frameworks"><meta name=twitter:description content="不得不感叹互联网真是太好了。近期在看一些 Agent 领域的论文时，发现无论如何都绕不开ReAct这个框架——它如此简洁，却又如此有效，真正体现了“大道至简”的思想。我在YouTube上找到了ReAct的作者Yao Shunyu的博士答辩。非常感谢这种无私的分享，让我获得了一次极其宝贵的学习机会。
视频链接：https://www.youtube.com/watch?v=zwfE6J2BIR4
注：文中所有的图都来自上面视频链接，文中不再注明
概览 Agent：
Rule-based agents: manual design 人工写规则
Learning-based agents: trial-and-error 靠试错学习
Language agents: reasoning to act 先用语言推理，再行动 Environment：
Interact with humans/physical world 与人交互
Interact with games/simulation 与游戏交互
Interact with the digital world (Internet) 与互联网交互 Challenges:
Accessible methods for general agents
Scalable benchmarks for practical tasks 主要的研究：
Part 1: Benchmarking agents via digital automation
Part 2: Building language agents that reason to act
Part 3: Principled framework for language agents"><meta itemprop=name content="2025-10-01 姚顺雨博士答辩总结 Language Agents_Benchmarks, Methods and Frameworks"><meta itemprop=description content="不得不感叹互联网真是太好了。近期在看一些 Agent 领域的论文时，发现无论如何都绕不开ReAct这个框架——它如此简洁，却又如此有效，真正体现了“大道至简”的思想。我在YouTube上找到了ReAct的作者Yao Shunyu的博士答辩。非常感谢这种无私的分享，让我获得了一次极其宝贵的学习机会。
视频链接：https://www.youtube.com/watch?v=zwfE6J2BIR4
注：文中所有的图都来自上面视频链接，文中不再注明
概览 Agent：
Rule-based agents: manual design 人工写规则
Learning-based agents: trial-and-error 靠试错学习
Language agents: reasoning to act 先用语言推理，再行动 Environment：
Interact with humans/physical world 与人交互
Interact with games/simulation 与游戏交互
Interact with the digital world (Internet) 与互联网交互 Challenges:
Accessible methods for general agents
Scalable benchmarks for practical tasks 主要的研究：
Part 1: Benchmarking agents via digital automation
Part 2: Building language agents that reason to act
Part 3: Principled framework for language agents"><meta itemprop=datePublished content="2025-10-01T14:11:50+00:00"><meta itemprop=dateModified content="2025-10-01T14:11:50+00:00"><meta itemprop=wordCount content="796"><meta itemprop=keywords content="Tech"><meta name=lang content="chs"></head><body class="dark:bg-gray-800 dark:text-white relative flex flex-col min-h-screen"><header class="container flex justify-between md:justify-between gap-4 flex-wrap p-6 mx-auto relative"><a href=https://huizhixu.github.io/chs/ class="capitalize font-extrabold text-2xl"><img src=../../../blist-logo.png alt=徐慧志的个人博客 class="h-8 max-w-full">
</a><button class="mobile-menu-button md:hidden">
<svg width="30" height="30" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><line x1="4" y1="8" x2="20" y2="8"/><line x1="4" y1="16" x2="20" y2="16"/></svg></button><ul class="mobile-menu absolute z-10 px-6 pb-6 md:p-0 top-full left-0 w-full md:w-auto md:relative hidden md:flex flex-col md:flex-row items-end md:items-center gap-4 lg:gap-6 bg-white dark:bg-gray-800"><li><a href=../../../chs/know_how/>技术</a></li><li><a href=../../../chs/life/>生活见闻</a></li><li><a href=../../../chs/page/about/>关于</a></li><li><a href=../../../chs/link/>宝藏集结</a></li><li><a href=../../../chs/tags/>分类</a></li><li class="relative cursor-pointer"><span class="language-switcher flex items-center gap-2"><svg width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="12" cy="12" r="9"/><line x1="3.6" y1="9" x2="20.4" y2="9"/><line x1="3.6" y1="15" x2="20.4" y2="15"/><path d="M11.5 3a17 17 0 000 18"/><path d="M12.5 3a17 17 0 010 18"/></svg>
<a>语言</a>
<svg width="14" height="14" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M18 15l-6-6-6 6h12" transform="rotate(180 12 12)"/></svg></span><div class="language-dropdown absolute top-full mt-2 left-0 flex-col gap-2 bg-gray-100 dark:bg-gray-900 dark:text-white z-10 hidden"><a class="px-3 py-2 hover:bg-gray-200 dark:hover:bg-gray-700" href=../../../en/ lang=en>English</a>
<a class="px-3 py-2 hover:bg-gray-200 dark:hover:bg-gray-700" href=../../../de/ lang=de>Deutsch</a></div></li><li class="grid place-items-center"><span class="open-search inline-block cursor-pointer"><svg width="20" height="20" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg></span></li><li class="grid place-items-center"><span class="toggle-dark-mode inline-block cursor-pointer"><svg width="24" height="24" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="12" cy="12" r="3"/><line x1="12" y1="5" x2="12" y2="5.01"/><line x1="17" y1="7" x2="17" y2="7.01"/><line x1="19" y1="12" x2="19" y2="12.01"/><line x1="17" y1="17" x2="17" y2="17.01"/><line x1="12" y1="19" x2="12" y2="19.01"/><line x1="7" y1="17" x2="7" y2="17.01"/><line x1="5" y1="12" x2="5" y2="12.01"/><line x1="7" y1="7" x2="7" y2="7.01"/></svg></span></li></ul></header><main class=flex-1><article class="prose lg:prose-lg mx-auto my-8 dark:prose-dark px-4"><h1 class="text-2xl font-bold mb-2">2025-10-01 姚顺雨博士答辩总结 Language Agents_Benchmarks, Methods and Frameworks</h1><h5 class="text-sm flex items-center flex-wrap"><svg class="mr-1" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><rect x="4" y="5" width="16" height="16" rx="2"/><line x1="16" y1="3" x2="16" y2="7"/><line x1="8" y1="3" x2="8" y2="7"/><line x1="4" y1="11" x2="20" y2="11"/><rect x="8" y="15" width="2" height="2"/></svg>
发布于
2025年10月01日
&nbsp;&bull;&nbsp;
<svg class="mr-1" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
4&nbsp;分钟
&nbsp;&bull;
<svg class="mx-1" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M3 19a9 9 0 019 0 9 9 0 019 0"/><path d="M3 6a9 9 0 019 0 9 9 0 019 0"/><line x1="3" y1="6" x2="3" y2="19"/><line x1="12" y1="6" x2="12" y2="19"/><line x1="21" y1="6" x2="21" y2="19"/></svg>
796&nbsp;字</h5><details id=TableOfContents class="px-4 mt-4 bg-gray-100 dark:bg-gray-700 rounded toc"><summary class="flex items-center font-bold py-2 px-4 cursor-pointer justify-between select-none text-black dark:text-white"><span>Table of contents</span>
<svg class="icon icon-tabler icon-tabler-chevron-down" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><polyline points="6 9 12 15 18 9"/></svg></summary><ul class="mt-2 pb-4"><li><a href=#%e6%a6%82%e8%a7%88>概览</a></li><li><a href=#part-1-benchmarking-agents-via-digital-automation>Part 1 Benchmarking agents via digital automation</a><ul><li><a href=#webshop>Webshop</a></li><li><a href=#%e6%80%bb%e7%bb%93>总结</a></li></ul></li><li><a href=#part-2-building-language-agents-that-reason-to-act>Part 2 Building language agents that reason to act</a><ul><li><a href=#react>ReAct</a></li><li><a href=#tree-of-thoughts>Tree of Thoughts</a></li><li><a href=#%e6%80%bb%e7%bb%93-1>总结</a></li></ul></li><li><a href=#part-3-principled-framework-for-language-agents>Part 3 Principled framework for language agents</a><ul><li><a href=#coala>CoALA</a></li></ul></li><li><a href=#future-work>Future work</a><ul><li><a href=#train-models-for-agents>Train models for agents</a></li><li><a href=#teach-and-discover-knowledge>Teach and discover knowledge</a></li></ul></li></ul></details><p>不得不感叹互联网真是太好了。近期在看一些 Agent 领域的论文时，发现无论如何都绕不开ReAct这个框架——它如此简洁，却又如此有效，真正体现了“大道至简”的思想。我在YouTube上找到了ReAct的作者Yao Shunyu的博士答辩。非常感谢这种无私的分享，让我获得了一次极其宝贵的学习机会。</p><p>视频链接：https://www.youtube.com/watch?v=zwfE6J2BIR4</p><p>注：文中所有的图都来自上面视频链接，文中不再注明</p><h1 id=概览>概览</h1><p>Agent：</p><ul><li><p>Rule-based agents: manual design 人工写规则</p></li><li><p>Learning-based agents: trial-and-error 靠试错学习</p></li><li><p>Language agents: reasoning to act 先用语言推理，再行动
Environment：</p></li><li><p>Interact with humans/physical world 与人交互</p></li><li><p>Interact with games/simulation 与游戏交互</p></li><li><p>Interact with the digital world (Internet) 与互联网交互
Challenges:</p></li><li><p>Accessible methods for general agents</p></li><li><p>Scalable benchmarks for practical tasks
主要的研究：</p></li><li><p>Part 1: Benchmarking agents via digital automation</p></li><li><p>Part 2: Building language agents that reason to act</p></li><li><p>Part 3: Principled framework for language agents</p></li></ul><h1 id=part-1-benchmarking-agents-via-digital-automation>Part 1 Benchmarking agents via digital automation</h1><p>Digital automation: tasks on the computer (写论文、跑实验、找文献、回邮件、debug、甚至和审稿人吵架) ，所有在电脑上能做的任务都可以被 automated，这叫 digital automation。</p><ul><li>Tremendous practical values, but little progress (think about Siri) 有很大的价值，但是进展有限。</li><li>Underlying research challenges: （所以有两点挑战：1. 基于真实世界的推理 2. 在开放环境中做长期决策）</li><li>解决这些对 robot navigation, planning, coordination 都很重要
不包含这些 digital automation 的 agent benchmarks 有 MiniWoB, TextWorld, BabyAI。它们的共同特点是 simulation environment, small action space, synthetic text and short-horizon tasks。</li></ul><h2 id=webshop>Webshop</h2><p>WebGPT： 输入一个问题，经过网页浏览器之后，得到一些输出，需要通过 professional annotators 标注才能知道哪些是对的，哪些是错的，才能有 reward。</p><p>Desired benchmark: 针对 complex environment 的 research challenges，但是重要的是有 automatic reward function。</p><p>所以开发了 Webshop，用户可以通过对话来买东西。它满足上面的条件：</p><ol><li>Large scale complex environment based on 1.16M</li><li>Automatic reward based on instruction and product attribute matching</li><li>Challenges language and visual understanding, and decision making
结果： 不管他们基于什么模型构建的 agent，性能（28.7%）还是达不到人类的一半。（模型有 Pre-trained image model (ResNet），Pre-trained language model (BERT, BART），imitation learning 和 reinforcement learning。</li></ol><p>Imitation learning 是指让智能体照着人类做。</p><ul><li>先收集人类专家完成任务的数据，通常是状态和动作。</li><li>然后用监督学习去拟合一个策略，复制人类行为。</li><li>训练完成后，智能体遇到新状态 s，就像人类那样直接输出动作 a。
Insight：</li></ul><ol><li>RL agent 的轨迹长度是 4.5，但是人类在这个任务上是 11.3，agent 不具有 long-horizon 的能力。</li><li>Webshop enables sim-to-real transfer。模拟→现实迁移（sim-to-real transfer）是指在 WebShop 这个模拟购物网站里训练好的语言智能体，不做任何额外微调，直接搬到真正的 Amazon、eBay 等真实网站上运行，仍能取得一定的成功率。
从 WebShop 开始，有大量的类似的 web interaction 的项目出现，探索 visual understanding, language understanding, decision making, planning, reinforcement learning 等方法。同时谷歌和 OpenAI 等也在这方面做了工业上的尝试。</li></ol><p><img src=https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251001/a460b60c.png alt></p><p>这个时候，Coding 的 benchmarks 也开始流行，例如 HumanEval，它的任务比较简单，只需要几行代码就能完成。在短短两年内，各路模型和系统将它的正确率从 25% 推到 95%。这个任务目前来说太简单了。</p><p>然后就有了 SWE-Bench。它的任务更难，输入是一个 GitHub repo 和 issue，输出是一个来解决这些 issue 的 file diff，它用 unit tests 来进行评估。</p><p>但是，仅仅依靠依靠大语言模型 sequence-to-sequence 的设置，不能解决 SWE-Bench 的难题。这里进行了一个测试，ChatGPT-3.5 解决了 0.2% 的问题，Claude 2 能解决 1.96%。</p><h2 id=总结>总结</h2><ol><li>Digital Automation is a new frontier for autonomous agents，它有巨大的价值，有 scalable environment，但是瓶颈在于 scalable evaluation。</li><li>Digital Automation 需要的是开放性语言环境下的连续决策（比如写代码、找论文、回邮件、debug、跑实验等），但是 LLM 和 RL agents 都不能完成这个任务，因此需要一种新型的 agents。</li></ol><h1 id=part-2-building-language-agents-that-reason-to-act>Part 2 Building language agents that reason to act</h1><p>LLM Reasoning 的发展</p><p>Language models can generate texts in a simple way predicting the next token auto-regressively.</p><p>In 2020 GPT-3 showed us LLMs can solve a variety of NLP tasks by giving them task instructions.</p><p>Followup research showed us LLMs can solve question answering tasks by giving them how to bridge the input and output with reasoning.</p><p>这个时候的 reasoning 指的是给定上下文，然后从里面挖掘出新的信息来更新 internal context。</p><p>LLMs can solve tasks using a few examples.</p><p>LLMs can reason to answer questions using Chain-of-Thought Prompting.</p><p>但是大模型推理存在问题：lack of knowledge and capabilities。</p><p>例子： 有 7 trillion 美元，能买下苹果、英伟达和微软吗？</p><p>GPT-4 会回答错误。原因有两个：1. 模型的知识是固定的和有限的。2. 模型不擅长做计算任务。</p><p>解决方法有很多，可以用检索来解决知识的有限，可以用 finetune 来解决计算。但是根本问题是模型自训练之初便被设计为文本生成器，而非能与环境交互、主动执行任务的智能体。</p><p>如果把环境和任务加到模型的训练里面去，那这个任务很难通用，因为推理时关于 actions, environment 和 tasks 的分布和训练时不一样。</p><p>但是人类有很少的知识也能够完成任务，因为人类会推理。</p><h2 id=react>ReAct</h2><p>ReAct 是一种结合了 reason 和 act 的 agent。</p><ul><li>Reasoning: update internal belief</li><li>Acting: obtain external feedback
区分 traditional agent 和 language agent</li></ul><p>（最大的区别是改变的是 external feedback 和 internal context。）</p><p>传统的 Agent： Acting space 完全由环境定义。每一步，会给 Agent context，context 包括外部的反馈以及之前的 agent action。基于 agent context 和最大化 reward 的思想选出下一步 agent action。</p><p><img src=https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251001/fcfeaa4f.png alt></p><p>Language agent: Acting space 在之前的基础上增加 reasoning 这种类型。reasoning 是一种特殊的 action。reasoning 可以是任何 language sequence，所以它是个无限空间。它没有任何外部的反馈，但是它会改变 agent 内部的上下文。</p><p><img src=https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251001/51309b92.png alt></p><p>具体如何实现：</p><p>只需要在 sample task 写出 what do you think, how you act to solve the task 就行。这个叫做 trajectory。</p><p>trajectory 包括 task, thought, action, observation</p><p>构建了很多这种 trajectory，甚至可以去 finetune 模型。</p><p>Zero-shot ReAct Prompt</p><p><img src=https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251001/5e3e7c50.png alt></p><p>作者做了一个对抗性实验，将外部反馈变为空或者给错误的外部反馈（这里通过改变搜索结果），结果发现模型一直可以根据反馈调整 Thought 和 Action。</p><p>这里可以看出并不是仅仅是提供外部结果、反馈以及工具的 action 来决定结果，reasoning 在其中起到了制定计划，重新制定计划，跟踪过程的作用。这是一种协同作用。</p><p>在前面的 Webshop 上，RL Agent 的成功率是 28.7%，只有 Act 的 Agent 成功率是 30.1%，而 ReAct 成功率是 40%。</p><p>把 ReAct 用在 SWE-Bench 上，成功率是 12.7%，相比，LLM 里面最高的成功率是 1.96%，Devin 的成功率是 13.86%。</p><h2 id=tree-of-thoughts>Tree of Thoughts</h2><p>搜索算法已经研究了几十年，为什么过去没把它用到自然语言推理上？</p><p>游戏： 24点</p><p>Next-token prediction cannot reason deliberately，因为 next-token prediction 是一个线性的机制，是从左到右的进行一个一个的 token 级别的预测。但是对于解决 24 点这个问题来说，需要一直去 backtrack 第一个数是不是合适的。对于 LLM 来说很难 backtrack，很难第一次就生成正确的数字。</p><p>Human recognition: Daniel Kahneman Thinking Fast and Slow</p><p>两种思考模式：</p><ul><li>System one: Fast and automatic （对应 next token prediction）</li><li>System two: Slow and deliberate （对应 control algorithm）
为什么 Tree Search 没有用来处理模型推理问题呢？因为 space of thinking 空间无限，并且没有反馈，所以不能 enumerate 或者 evaluate。但是传统的搜索是可以做暴力枚举的，象棋游戏也能够写出 evaluate 函数。</li></ul><p>但是如果定义一个小的 thinking space，也有一个足够好的外部反馈，那其实是可行的。Tree of Thoughts 用 24 点来做其实是选了一个很好的例子，将问题限制在某一个范围内了。</p><p>Tree of Thoughts 的关键思想是语言不仅仅是无限的，它实际上是有 compositional meaning 的，有 semantically coherent units of text。</p><p>Tree of thought 关键在于 thought，如果把每一个 token 看成一个 thought，那么它会很容易 generate 但是很难 evaluate。</p><p>如果把 whole reasoning 看成一个 thought，它很容易 evaluate，很难 generate。</p><p>那么取中间值，把每一个等式作为一个 thought，它相对来说 generate 和 evaluate 都很容易。</p><p>所以这里的 thought 就是 a semantically coherent unit text that can be generated and evaluated by LLMs。</p><p>那么就可以完成任务了，步骤如下：</p><ol><li>generate: 用 LLM 一次性写 k 条不同的等式。</li><li>evaluate: 用 LLM 给每条方程式打分，留下分数高的。</li><li>继续循环。</li></ol><h2 id=总结-1>总结</h2><ul><li>ReAct： reasoning 是 agents 的 internal action （思考与执行互补）</li><li>ToT： reasoning and acting can be similarly planned （统一思考与执行）</li></ul><h1 id=part-3-principled-framework-for-language-agents>Part 3 Principled framework for language agents</h1><p>这一部分旨在从上面的经验中跳脱出来，形成一个包罗万象的框架。</p><ul><li>How do we make sense of the various LLM Systems?</li><li>How do we understand them even though they&rsquo;re defining very different tasks and concepts?
因为需要给一个概念性的理解，而不是仅仅从经验出发去解决一个问题。这样才能知道接下来这个领域往哪里走。</li></ul><h2 id=coala>CoALA</h2><p>CoALA 指 Cognitive Architectures for Language Agents，它包括三个关键概念。</p><ol><li>Memory: short and long term</li><li>Action Space: internal and external</li><li>Decision making: choose an action
这个框架能够让我们快速地比较不同的 agent 论文和方法。因为这三个概念是 agent 的精华。</li></ol><h1 id=future-work>Future work</h1><h2 id=train-models-for-agents>Train models for agents</h2><p>Establish model-agent synergy，可以借鉴 GPU 和 deep learning 的发展。</p><ol><li>增强 agent 系统层面能做到的事，例如 planning, self-evaluation, calibration。</li><li>开源的 agent 基座模型。</li><li>规模：训练语料再上一个量级 Next trillion tokens for model training。</li></ol><h2 id=teach-and-discover-knowledge>Teach and discover knowledge</h2><p>不是模仿已有的知识，而是挖掘新知识。</p><p>Language agents 有望成为最好的教授，或者是最好的学生，用来反哺人类。</p><p>在个性化教育和科学研究方面起到作用。主要涉及到的领域可能为：</p><ul><li>Flexible learning and retrieval (Long-term memory)</li><li>Intrinsic motivation
原因：</li></ul><ol><li>现在的 agent 完不成真正的个性化教育，因为缺一个能一直记录、更新、检索学生所有交互的长期记忆系统，而且不能给每个学生都重新训一个模型。</li><li>做科研型 agent 也不行，因为科研是开放式任务，没有明确奖励，人类靠好奇心继续探索，agent 缺少这种内在动机机制。</li></ol></article><div class="px-2 mb-2"><script src=https://utteranc.es/client.js repo=HuizhiXu/huizhixu.github.io issue-term=pathname theme=github-light crossorigin=anonymous async></script></div><div class="bg-blue-100 dark:bg-gray-900"><div class="container px-4 py-12 mx-auto max-w-4xl grid grid-cols-1 md:grid-cols-2 gap-4 items-center"><div><div class="text-2xl font-bold mb-2">Sein heißt werden, leben heißt lernen.</div><p class=opacity-60>Der einfache Weg is immer verkehrt.</p></div><ul class="flex justify-center gap-x-3 flex-wrap gap-y-2"><li><a href=https://twitter.com/ target=_blank rel=noopener aria-label=Twitter class="p-1 inline-block rounded-full border border-transparent text-gray-500 hover:text-gray-800 hover:border-gray-800 cursor-pointer transition-colors dark:text-gray-600 dark:hover:border-gray-300 dark:hover:text-gray-300"><svg width="24" height="24" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M22 4.01c-1 .49-1.98.689-3 .99-1.121-1.265-2.783-1.335-4.38-.737S11.977 6.323 12 8v1c-3.245.083-6.135-1.395-8-4 0 0-4.182 7.433 4 11-1.872 1.247-3.739 2.088-6 2 3.308 1.803 6.913 2.423 10.034 1.517 3.58-1.04 6.522-3.723 7.651-7.742a13.84 13.84.0 00.497-3.753C20.18 7.773 21.692 5.25 22 4.009z"/></svg></a></li><li><a href=https://github.com/ target=_blank rel=noopener aria-label=GitHub class="p-1 inline-block rounded-full border border-transparent text-gray-500 hover:text-gray-800 hover:border-gray-800 cursor-pointer transition-colors dark:text-gray-600 dark:hover:border-gray-300 dark:hover:text-gray-300"><svg width="24" height="24" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ul></div></div></main><footer class="container p-6 mx-auto flex justify-between items-center"><span class="text-sm font-light">Copyright © 2012 - Huizhi Xu · All rights reserved
</span><span onclick='window.scrollTo({top:0,behavior:"smooth"})' class="p-1 cursor-pointer"><svg width="30" height="30" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M18 15l-6-6-6 6h12"/></svg></span></footer><div class="search-ui absolute top-0 left-0 w-full h-full bg-white dark:bg-gray-800 hidden"><div class="container max-w-3xl mx-auto p-12"><div class=relative><div class="my-4 text-center text-2xl font-bold">Search</div><span class="p-2 absolute right-0 top-0 cursor-pointer close-search"><svg width="24" height="24" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><line x1="18" y1="6" x2="6" y2="18"/><line x1="6" y1="6" x2="18" y2="18"/></svg></span></div><input type=search class="py-2 px-3 w-full dark:text-black border dark:border-transparent" placeholder="Enter search query"><div class="search-results text-lg font-medium my-4 hidden">Results</div><ul class="search-list my-2"></ul><div class="no-results text-center my-8 hidden"><div class="text-xl font-semibold mb-2">No results found</div><p class="font-light text-sm">Try adjusting your search query</p></div></div></div><script src=https://huizhixu.github.io/js/scripts.min.js></script><script>const languageMenuButton=document.querySelector(".language-switcher"),languageDropdown=document.querySelector(".language-dropdown");languageMenuButton.addEventListener("click",e=>{e.preventDefault(),languageDropdown.classList.contains("hidden")?(languageDropdown.classList.remove("hidden"),languageDropdown.classList.add("flex")):(languageDropdown.classList.add("hidden"),languageDropdown.classList.remove("flex"))})</script><script>const darkmode=document.querySelector(".toggle-dark-mode");function toggleDarkMode(){document.documentElement.classList.contains("dark")?(document.documentElement.classList.remove("dark"),localStorage.setItem("darkmode","light")):(document.documentElement.classList.add("dark"),localStorage.setItem("darkmode","dark"))}darkmode&&darkmode.addEventListener("click",toggleDarkMode);const darkStorage=localStorage.getItem("darkmode"),isBrowserDark=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches;!darkStorage&&isBrowserDark&&document.documentElement.classList.add("dark"),darkStorage&&darkStorage==="dark"&&toggleDarkMode()</script><script>const mobileMenuButton=document.querySelector(".mobile-menu-button"),mobileMenu=document.querySelector(".mobile-menu");function toggleMenu(){mobileMenu.classList.toggle("hidden"),mobileMenu.classList.toggle("flex")}mobileMenu&&mobileMenuButton&&mobileMenuButton.addEventListener("click",toggleMenu)</script></body></html>