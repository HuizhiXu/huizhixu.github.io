<!DOCTYPE html>
<html lang="chs" itemscope itemtype="http://schema.org/WebPage"><head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <link rel="icon" href="../../../favicon.svg">

  <title>
  2025-11-01 从零构建大模型—通过微调遵循人类指令 - 徐慧志的个人博客
  </title>
  <meta name="description" content="终于来到这本书的最后一章啦。
这本书的整体脉络非常清晰：从最初的输入处理，逐步深入到自注意力机制、因果自注意力，再到亲手实现一个大模型，接着进行预训练，并最终完成分类微调和指令微调。完成整个学习过程后，确实感到收获颇丰。（个人觉得第三、四章的内容最为关键）
当然我也清楚，还有很多细节需要进一步补充，比如训练过程中的各种技巧、多卡并行操作，以及参数高效微调等等。这些都是我接下来会继续学习的内容。
接下来是本章的内容：
预训练后的大模型能够实现文本补全——给定一个文本片段作为输入，模型能够继续生成后续内容。
但如果希望模型能够遵循指令、生成合理回复，就需要进行指令微调。
这一部分的实现流程和上一章很相似，主要区别在于数据集的格式。依然分为三个阶段来完成。
第一阶段：数据准备
包括下载数据集、进行数据预处理以及构建数据加载器。
第二阶段：模型微调
包括加载预训练大语言模型、执行指令微调以及监控模型损失。
第三阶段：评估大语言模型
包括提取模型回复、进行量化评估以及对生成内容打分。
第一阶段：数据准备
1. 下载数据
可以使用网上已有的数据集：
url = &#34;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/instruction-data.json&#34;
指令微调所需的数据是“输入-输出”对。例如：

 {&#39;instruction&#39;: &#39;Identify the correct spelling of the following word.&#39;,
  &#39;input&#39;: &#39;Ocassion&#39;, 
  &#39;output&#39;: &#34;The correct spelling is &#39;Occasion.&#39;&#34;}
为了适配大模型的输入格式，还需要将数据加工成如下形式。这种“###”分隔的格式，是从概率角度帮助模型识别结构：

 Below is an instruction that describe a task. Write a response that appropriately
 complete the request.
 
 ### Instruction:
 Identify the correct spelling of the following word.
 
 ### Input:
 Ocassion
 
 ### Output
The correct spelling is &#39;Occasion&#39;.
2. 数据集预处理
数据下载后，需要将样本填充至相同长度，并进行批次处理。" /><meta name="generator" content="Hugo 0.135.0"><link
    rel="stylesheet"
    href="/css/styles.min.9af39941a3807f10eba8dd56da5fe9f28076ed2722ec76c1aa643b6d55afedbd.css"
    integrity=""
    crossorigin="anonymous"
  />
  
  

  
  <meta property="og:url" content="https://huizhixu.github.io/chs/know_how/20251101-%E4%BB%8E%E9%9B%B6%E6%9E%84%E5%BB%BA%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%80%9A%E8%BF%87%E5%BE%AE%E8%B0%83%E9%81%B5%E5%BE%AA%E4%BA%BA%E7%B1%BB%E6%8C%87%E4%BB%A4/">
  <meta property="og:site_name" content="徐慧志的个人博客">
  <meta property="og:title" content="2025-11-01 从零构建大模型—通过微调遵循人类指令">
  <meta property="og:description" content="终于来到这本书的最后一章啦。
这本书的整体脉络非常清晰：从最初的输入处理，逐步深入到自注意力机制、因果自注意力，再到亲手实现一个大模型，接着进行预训练，并最终完成分类微调和指令微调。完成整个学习过程后，确实感到收获颇丰。（个人觉得第三、四章的内容最为关键）
当然我也清楚，还有很多细节需要进一步补充，比如训练过程中的各种技巧、多卡并行操作，以及参数高效微调等等。这些都是我接下来会继续学习的内容。
接下来是本章的内容：
预训练后的大模型能够实现文本补全——给定一个文本片段作为输入，模型能够继续生成后续内容。 但如果希望模型能够遵循指令、生成合理回复，就需要进行指令微调。
这一部分的实现流程和上一章很相似，主要区别在于数据集的格式。依然分为三个阶段来完成。
第一阶段：数据准备
包括下载数据集、进行数据预处理以及构建数据加载器。
第二阶段：模型微调
包括加载预训练大语言模型、执行指令微调以及监控模型损失。
第三阶段：评估大语言模型
包括提取模型回复、进行量化评估以及对生成内容打分。
第一阶段：数据准备 1. 下载数据 可以使用网上已有的数据集：
url = &#34;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/instruction-data.json&#34; 指令微调所需的数据是“输入-输出”对。例如：
{&#39;instruction&#39;: &#39;Identify the correct spelling of the following word.&#39;, &#39;input&#39;: &#39;Ocassion&#39;, &#39;output&#39;: &#34;The correct spelling is &#39;Occasion.&#39;&#34;} 为了适配大模型的输入格式，还需要将数据加工成如下形式。这种“###”分隔的格式，是从概率角度帮助模型识别结构：
Below is an instruction that describe a task. Write a response that appropriately complete the request. ### Instruction: Identify the correct spelling of the following word. ### Input: Ocassion ### Output The correct spelling is &#39;Occasion&#39;. 2. 数据集预处理 数据下载后，需要将样本填充至相同长度，并进行批次处理。">
  <meta property="og:locale" content="chs">
  <meta property="og:type" content="article">
    <meta property="article:section" content="know_how">
    <meta property="article:published_time" content="2025-11-01T13:55:35+00:00">
    <meta property="article:modified_time" content="2025-11-01T13:55:35+00:00">
    <meta property="article:tag" content="Tech">

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="2025-11-01 从零构建大模型—通过微调遵循人类指令">
  <meta name="twitter:description" content="终于来到这本书的最后一章啦。
这本书的整体脉络非常清晰：从最初的输入处理，逐步深入到自注意力机制、因果自注意力，再到亲手实现一个大模型，接着进行预训练，并最终完成分类微调和指令微调。完成整个学习过程后，确实感到收获颇丰。（个人觉得第三、四章的内容最为关键）
当然我也清楚，还有很多细节需要进一步补充，比如训练过程中的各种技巧、多卡并行操作，以及参数高效微调等等。这些都是我接下来会继续学习的内容。
接下来是本章的内容：
预训练后的大模型能够实现文本补全——给定一个文本片段作为输入，模型能够继续生成后续内容。 但如果希望模型能够遵循指令、生成合理回复，就需要进行指令微调。
这一部分的实现流程和上一章很相似，主要区别在于数据集的格式。依然分为三个阶段来完成。
第一阶段：数据准备
包括下载数据集、进行数据预处理以及构建数据加载器。
第二阶段：模型微调
包括加载预训练大语言模型、执行指令微调以及监控模型损失。
第三阶段：评估大语言模型
包括提取模型回复、进行量化评估以及对生成内容打分。
第一阶段：数据准备 1. 下载数据 可以使用网上已有的数据集：
url = &#34;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/instruction-data.json&#34; 指令微调所需的数据是“输入-输出”对。例如：
{&#39;instruction&#39;: &#39;Identify the correct spelling of the following word.&#39;, &#39;input&#39;: &#39;Ocassion&#39;, &#39;output&#39;: &#34;The correct spelling is &#39;Occasion.&#39;&#34;} 为了适配大模型的输入格式，还需要将数据加工成如下形式。这种“###”分隔的格式，是从概率角度帮助模型识别结构：
Below is an instruction that describe a task. Write a response that appropriately complete the request. ### Instruction: Identify the correct spelling of the following word. ### Input: Ocassion ### Output The correct spelling is &#39;Occasion&#39;. 2. 数据集预处理 数据下载后，需要将样本填充至相同长度，并进行批次处理。">

  
  <meta itemprop="name" content="2025-11-01 从零构建大模型—通过微调遵循人类指令">
  <meta itemprop="description" content="终于来到这本书的最后一章啦。
这本书的整体脉络非常清晰：从最初的输入处理，逐步深入到自注意力机制、因果自注意力，再到亲手实现一个大模型，接着进行预训练，并最终完成分类微调和指令微调。完成整个学习过程后，确实感到收获颇丰。（个人觉得第三、四章的内容最为关键）
当然我也清楚，还有很多细节需要进一步补充，比如训练过程中的各种技巧、多卡并行操作，以及参数高效微调等等。这些都是我接下来会继续学习的内容。
接下来是本章的内容：
预训练后的大模型能够实现文本补全——给定一个文本片段作为输入，模型能够继续生成后续内容。 但如果希望模型能够遵循指令、生成合理回复，就需要进行指令微调。
这一部分的实现流程和上一章很相似，主要区别在于数据集的格式。依然分为三个阶段来完成。
第一阶段：数据准备
包括下载数据集、进行数据预处理以及构建数据加载器。
第二阶段：模型微调
包括加载预训练大语言模型、执行指令微调以及监控模型损失。
第三阶段：评估大语言模型
包括提取模型回复、进行量化评估以及对生成内容打分。
第一阶段：数据准备 1. 下载数据 可以使用网上已有的数据集：
url = &#34;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/instruction-data.json&#34; 指令微调所需的数据是“输入-输出”对。例如：
{&#39;instruction&#39;: &#39;Identify the correct spelling of the following word.&#39;, &#39;input&#39;: &#39;Ocassion&#39;, &#39;output&#39;: &#34;The correct spelling is &#39;Occasion.&#39;&#34;} 为了适配大模型的输入格式，还需要将数据加工成如下形式。这种“###”分隔的格式，是从概率角度帮助模型识别结构：
Below is an instruction that describe a task. Write a response that appropriately complete the request. ### Instruction: Identify the correct spelling of the following word. ### Input: Ocassion ### Output The correct spelling is &#39;Occasion&#39;. 2. 数据集预处理 数据下载后，需要将样本填充至相同长度，并进行批次处理。">
  <meta itemprop="datePublished" content="2025-11-01T13:55:35+00:00">
  <meta itemprop="dateModified" content="2025-11-01T13:55:35+00:00">
  <meta itemprop="wordCount" content="589">
  <meta itemprop="keywords" content="Tech">

  
  <meta name="lang" content="chs" />
  

  
</head>
<body class="dark:bg-gray-800 dark:text-white relative flex flex-col min-h-screen"><header class="container flex justify-between md:justify-between gap-4 flex-wrap p-6 mx-auto relative">
  <a href="https://huizhixu.github.io/chs/" class="capitalize font-extrabold text-2xl">
    
    <img src="../../../blist-logo.png" alt="徐慧志的个人博客" class="h-8 max-w-full" />
    
  </a>
  <button class="mobile-menu-button md:hidden">
    <svg xmlns="http://www.w3.org/2000/svg" width="30" height="30" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <line x1="4" y1="8" x2="20" y2="8" />
      <line x1="4" y1="16" x2="20" y2="16" />
    </svg>
  </button>
  <ul class="mobile-menu absolute z-10 px-6 pb-6 md:p-0 top-full left-0 w-full md:w-auto md:relative hidden md:flex flex-col md:flex-row items-end md:items-center gap-4 lg:gap-6 bg-white dark:bg-gray-800">

    
    <li><a href="../../../chs/know_how/">技术</a></li>
    
    <li><a href="../../../chs/life/">生活见闻</a></li>
    
    <li><a href="../../../chs/page/about/">关于</a></li>
    
    <li><a href="../../../chs/link/">宝藏集结</a></li>
    
    <li><a href="../../../chs/tags/">分类</a></li>
    

    
    
    <li class="relative cursor-pointer">
      <span class="language-switcher flex items-center gap-2">
        <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24"
          stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
          <path stroke="none" d="M0 0h24v24H0z" fill="none" />
          <circle cx="12" cy="12" r="9" />
          <line x1="3.6" y1="9" x2="20.4" y2="9" />
          <line x1="3.6" y1="15" x2="20.4" y2="15" />
          <path d="M11.5 3a17 17 0 0 0 0 18" />
          <path d="M12.5 3a17 17 0 0 1 0 18" />
        </svg>
        <a>语言</a>
        <svg xmlns="http://www.w3.org/2000/svg" width="14" height="14"
          viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round"
          stroke-linejoin="round">
          <path stroke="none" d="M0 0h24v24H0z" fill="none" />
          <path d="M18 15l-6 -6l-6 6h12" transform="rotate(180 12 12)" />
        </svg>
      </span>
      <div
        class="language-dropdown absolute top-full mt-2 left-0 flex-col gap-2 bg-gray-100 dark:bg-gray-900 dark:text-white z-10 hidden">
        
        
        
        
        <a class="px-3 py-2 hover:bg-gray-200 dark:hover:bg-gray-700" href="../../../en/" lang="en">English</a>
        
        
        
        <a class="px-3 py-2 hover:bg-gray-200 dark:hover:bg-gray-700" href="../../../de/" lang="de">Deutsch</a>
        
        
      </div>
    </li>
    
    

    
    <li class="grid place-items-center">
      <span class="open-search inline-block cursor-pointer">
        <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" stroke-width="1.5"
          stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
          <path stroke="none" d="M0 0h24v24H0z" fill="none" />
          <circle cx="10" cy="10" r="7" />
          <line x1="21" y1="21" x2="15" y2="15" />
        </svg>
      </span>
    </li>
    

    
    <li class="grid place-items-center">
      <span class="toggle-dark-mode inline-block cursor-pointer">
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke-width="1.5"
          stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
          <path stroke="none" d="M0 0h24v24H0z" fill="none" />
          <circle cx="12" cy="12" r="3" />
          <line x1="12" y1="5" x2="12" y2="5.01" />
          <line x1="17" y1="7" x2="17" y2="7.01" />
          <line x1="19" y1="12" x2="19" y2="12.01" />
          <line x1="17" y1="17" x2="17" y2="17.01" />
          <line x1="12" y1="19" x2="12" y2="19.01" />
          <line x1="7" y1="17" x2="7" y2="17.01" />
          <line x1="5" y1="12" x2="5" y2="12.01" />
          <line x1="7" y1="7" x2="7" y2="7.01" />
        </svg>
      </span>
    </li>
    
  </ul>
</header>
<main class="flex-1">
  
  

  

  <article class="prose lg:prose-lg mx-auto my-8 dark:prose-dark px-4">

    <h1 class="text-2xl font-bold mb-2">2025-11-01 从零构建大模型—通过微调遵循人类指令</h1>
    
    <h5 class="text-sm flex items-center flex-wrap">
      <svg xmlns="http://www.w3.org/2000/svg" class="mr-1" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
        <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
        <rect x="4" y="5" width="16" height="16" rx="2" />
        <line x1="16" y1="3" x2="16" y2="7" />
        <line x1="8" y1="3" x2="8" y2="7" />
        <line x1="4" y1="11" x2="20" y2="11" />
        <rect x="8" y="15" width="2" height="2" />
      </svg>
      发布于 
  
    2025年11月01日
  

      
        &nbsp;&bull;&nbsp;
      
      <svg xmlns="http://www.w3.org/2000/svg" class="mr-1" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
        <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
        <circle cx="12" cy="12" r="9" />
        <polyline points="12 7 12 12 15 15" />
      </svg>
     3&nbsp;分钟
     
      &nbsp;&bull;
      <svg xmlns="http://www.w3.org/2000/svg" class="mx-1" width="16" height="16" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
        <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
        <path d="M3 19a9 9 0 0 1 9 0a9 9 0 0 1 9 0" />
        <path d="M3 6a9 9 0 0 1 9 0a9 9 0 0 1 9 0" />
        <line x1="3" y1="6" x2="3" y2="19" />
        <line x1="12" y1="6" x2="12" y2="19" />
        <line x1="21" y1="6" x2="21" y2="19" />
      </svg>
      589&nbsp;字

    </h5>
    

    <details id="TableOfContents" class="px-4 mt-4 bg-gray-100 dark:bg-gray-700 rounded toc">
    <summary class="flex items-center font-bold py-2 px-4 cursor-pointer justify-between select-none text-black dark:text-white">
      <span>Table of contents</span>
      <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-chevron-down" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
        <path stroke="none" d="M0 0h24v24H0z" fill="none"></path>
        <polyline points="6 9 12 15 18 9"></polyline>
     </svg>
    </summary>

    <ul class="mt-2 pb-4">
        

        
        <li>
        <a href="#%e7%ac%ac%e4%b8%80%e9%98%b6%e6%ae%b5%e6%95%b0%e6%8d%ae%e5%87%86%e5%a4%87">第一阶段：数据准备</a>
        

        
        <ul>
            <li>
        <a href="#1-%e4%b8%8b%e8%bd%bd%e6%95%b0%e6%8d%ae">1. 下载数据</a>
        

        
        </li><li>
        <a href="#2-%e6%95%b0%e6%8d%ae%e9%9b%86%e9%a2%84%e5%a4%84%e7%90%86">2. 数据集预处理</a>
        

        
        </li><li>
        <a href="#3-%e5%88%9b%e5%bb%ba%e6%95%b0%e6%8d%ae%e5%8a%a0%e8%bd%bd%e5%99%a8">3. 创建数据加载器</a>
        

        
        </li></ul>
      </li><li>
        <a href="#%e7%ac%ac%e4%ba%8c%e9%98%b6%e6%ae%b5%e6%a8%a1%e5%9e%8b%e5%be%ae%e8%b0%83">第二阶段：模型微调</a>
        

        
        <ul>
            <li>
        <a href="#1-%e6%a8%a1%e5%9e%8b%e5%88%9d%e5%a7%8b%e5%8c%96">1. 模型初始化</a>
        

        
        </li><li>
        <a href="#2-%e5%8a%a0%e8%bd%bd%e9%a2%84%e8%ae%ad%e7%bb%83%e6%9d%83%e9%87%8d">2. 加载预训练权重</a>
        

        
        </li><li>
        <a href="#3-%e7%9c%8b%e6%a8%a1%e5%9e%8b%e5%be%ae%e8%b0%83%e4%b9%8b%e5%89%8d%e7%9a%84%e7%bb%93%e6%9e%9c%e5%92%8closs">3. 看模型微调之前的结果和loss</a>
        

        
        </li><li>
        <a href="#4--%e8%ae%ad%e7%bb%83%e4%bb%a3%e7%a0%81%e5%ae%9e%e7%8e%b0">4 . 训练代码实现</a>
        

        
        </li></ul>
      </li><li>
        <a href="#%e7%ac%ac%e4%b8%89%e9%98%b6%e6%ae%b5%e8%af%84%e4%bc%b0%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b">第三阶段：评估大语言模型</a>
        </li></ul>
  </details>

    <p>终于来到这本书的最后一章啦。</p>
<p>这本书的整体脉络非常清晰：从最初的输入处理，逐步深入到自注意力机制、因果自注意力，再到亲手实现一个大模型，接着进行预训练，并最终完成分类微调和指令微调。完成整个学习过程后，确实感到收获颇丰。（个人觉得第三、四章的内容最为关键）</p>
<p>当然我也清楚，还有很多细节需要进一步补充，比如训练过程中的各种技巧、多卡并行操作，以及参数高效微调等等。这些都是我接下来会继续学习的内容。</p>
<p>接下来是本章的内容：</p>
<p>预训练后的大模型能够实现文本补全——给定一个文本片段作为输入，模型能够继续生成后续内容。
但如果希望模型能够遵循指令、生成合理回复，就需要进行指令微调。</p>
<p>这一部分的实现流程和上一章很相似，主要区别在于数据集的格式。依然分为三个阶段来完成。</p>
<p>第一阶段：数据准备</p>
<p>包括下载数据集、进行数据预处理以及构建数据加载器。</p>
<p>第二阶段：模型微调</p>
<p>包括加载预训练大语言模型、执行指令微调以及监控模型损失。</p>
<p>第三阶段：评估大语言模型</p>
<p>包括提取模型回复、进行量化评估以及对生成内容打分。</p>
<h2 id="第一阶段数据准备">第一阶段：数据准备</h2>
<h3 id="1-下载数据">1. 下载数据</h3>
<p>可以使用网上已有的数据集：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>url <span style="color:#ff79c6">=</span> <span style="color:#f1fa8c">&#34;https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/instruction-data.json&#34;</span>
</span></span></code></pre></div><p>指令微调所需的数据是“输入-输出”对。例如：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span> {<span style="color:#f1fa8c">&#39;instruction&#39;</span>: <span style="color:#f1fa8c">&#39;Identify the correct spelling of the following word.&#39;</span>,
</span></span><span style="display:flex;"><span>  <span style="color:#f1fa8c">&#39;input&#39;</span>: <span style="color:#f1fa8c">&#39;Ocassion&#39;</span>, 
</span></span><span style="display:flex;"><span>  <span style="color:#f1fa8c">&#39;output&#39;</span>: <span style="color:#f1fa8c">&#34;The correct spelling is &#39;Occasion.&#39;&#34;</span>}
</span></span></code></pre></div><p>为了适配大模型的输入格式，还需要将数据加工成如下形式。这种“###”分隔的格式，是从概率角度帮助模型识别结构：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span> Below <span style="color:#ff79c6">is</span> an instruction that describe a task<span style="color:#ff79c6">.</span> Write a response that appropriately
</span></span><span style="display:flex;"><span> complete the request<span style="color:#ff79c6">.</span>
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span> <span style="color:#6272a4">### Instruction:</span>
</span></span><span style="display:flex;"><span> Identify the correct spelling of the following word<span style="color:#ff79c6">.</span>
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span> <span style="color:#6272a4">### Input:</span>
</span></span><span style="display:flex;"><span> Ocassion
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span> <span style="color:#6272a4">### Output</span>
</span></span><span style="display:flex;"><span>The correct spelling <span style="color:#ff79c6">is</span> <span style="color:#f1fa8c">&#39;Occasion&#39;</span><span style="color:#ff79c6">.</span>
</span></span></code></pre></div><h3 id="2-数据集预处理">2. 数据集预处理</h3>
<p>数据下载后，需要将样本填充至相同长度，并进行批次处理。</p>
<p>可以通过 PyTorch 的 DataLoader 类来构建训练批次。由于预处理逻辑较为复杂，这里需要自定义一个 collate_fn 函数。</p>
<p>主要步骤如下：</p>
<ol>
<li>使用提示词模板格式化数据</li>
<li>对格式化文本进行词元化（tokenize）</li>
<li>使用填充词元统一序列长度</li>
<li>创建目标词元 ID 用于训练</li>
<li>使用占位符替换部分填充词元</li>
</ol>
<p>其中有一个关键操作：</p>
<p>inputs = torch.tensor(padded[:-1])
targets = torch.tensor(padded[1:])</p>
<p>这个操作的意思是：向左移动一个词元的位置，然后将输入序列的第一个词元忽略，最后在尾部加入结束符词元即可得到其对应的目标序列。结束词元设为-100，这样在计算损失时可以排除填充词元的影响，确保只有有效数据参与模型学习。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#ff79c6">class</span> <span style="color:#50fa7b">InstructionDataset</span>(Dataset):
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">def</span> __init__(self, data, tokenizer):
</span></span><span style="display:flex;"><span>        self<span style="color:#ff79c6">.</span>data <span style="color:#ff79c6">=</span> data
</span></span><span style="display:flex;"><span>        self<span style="color:#ff79c6">.</span>tokenizer <span style="color:#ff79c6">=</span> tokenizer
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        self<span style="color:#ff79c6">.</span>encoded_texts <span style="color:#ff79c6">=</span> []
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">for</span> entry <span style="color:#ff79c6">in</span> data:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            input_text, full_formatted_text <span style="color:#ff79c6">=</span> format_input(entry)
</span></span><span style="display:flex;"><span>            encoded_text <span style="color:#ff79c6">=</span> self<span style="color:#ff79c6">.</span>tokenizer<span style="color:#ff79c6">.</span>encode(full_formatted_text)
</span></span><span style="display:flex;"><span>            self<span style="color:#ff79c6">.</span>encoded_texts<span style="color:#ff79c6">.</span>append(encoded_text)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">def</span> __len__(self):
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">return</span> <span style="color:#8be9fd;font-style:italic">len</span>(self<span style="color:#ff79c6">.</span>data)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">def</span> __getitem__(self, idx):
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">return</span> self<span style="color:#ff79c6">.</span>encoded_texts[idx]
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">def</span> <span style="color:#50fa7b">custom_collate_fn</span>(batch,pad_token_id<span style="color:#ff79c6">=</span><span style="color:#bd93f9">50256</span>,
</span></span><span style="display:flex;"><span>ignore_index<span style="color:#ff79c6">=-</span><span style="color:#bd93f9">100</span>, allowed_max_length<span style="color:#ff79c6">=</span><span style="color:#ff79c6">None</span>):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    batch_max_len <span style="color:#ff79c6">=</span> <span style="color:#8be9fd;font-style:italic">max</span>(<span style="color:#8be9fd;font-style:italic">len</span>(seq)<span style="color:#ff79c6">+</span><span style="color:#bd93f9">1</span> <span style="color:#ff79c6">for</span> seq <span style="color:#ff79c6">in</span> batch)
</span></span><span style="display:flex;"><span>    inputs_list,targets_list <span style="color:#ff79c6">=</span>[],[]
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">for</span> item <span style="color:#ff79c6">in</span> batch:
</span></span><span style="display:flex;"><span>        new_item <span style="color:#ff79c6">=</span> item<span style="color:#ff79c6">.</span>copy()
</span></span><span style="display:flex;"><span>        new_item <span style="color:#ff79c6">+=</span> [pad_token_id]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        padded <span style="color:#ff79c6">=</span> new_item <span style="color:#ff79c6">+</span> [pad_token_id] <span style="color:#ff79c6">*</span> (batch_max_len <span style="color:#ff79c6">-</span> <span style="color:#8be9fd;font-style:italic">len</span>(new_item))
</span></span><span style="display:flex;"><span>        inputs <span style="color:#ff79c6">=</span> torch<span style="color:#ff79c6">.</span>tensor(padded[:<span style="color:#ff79c6">-</span><span style="color:#bd93f9">1</span>])
</span></span><span style="display:flex;"><span>        targets <span style="color:#ff79c6">=</span> torch<span style="color:#ff79c6">.</span>tensor(padded[<span style="color:#bd93f9">1</span>:])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        mask <span style="color:#ff79c6">=</span> targets <span style="color:#ff79c6">==</span>pad_token_id
</span></span><span style="display:flex;"><span>        indices <span style="color:#ff79c6">=</span> torch<span style="color:#ff79c6">.</span>nonzero(mask)<span style="color:#ff79c6">.</span>squeeze()
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">if</span> indices<span style="color:#ff79c6">.</span>numel()<span style="color:#ff79c6">&gt;</span><span style="color:#bd93f9">1</span>:
</span></span><span style="display:flex;"><span>            targets[indices[<span style="color:#bd93f9">1</span>:]] <span style="color:#ff79c6">=</span> ignore_index
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">if</span> allowed_max_length <span style="color:#ff79c6">is</span> <span style="color:#ff79c6">not</span> <span style="color:#ff79c6">None</span>:
</span></span><span style="display:flex;"><span>            inputs <span style="color:#ff79c6">=</span> inputs[:allowed_max_length]
</span></span><span style="display:flex;"><span>            targets <span style="color:#ff79c6">=</span> targets[:allowed_max_length]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        inputs_list<span style="color:#ff79c6">.</span>append(inputs)
</span></span><span style="display:flex;"><span>        targets_list<span style="color:#ff79c6">.</span>append(targets)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    inputs_tensor <span style="color:#ff79c6">=</span> torch<span style="color:#ff79c6">.</span>stack(inputs_list)
</span></span><span style="display:flex;"><span>    targets_tensor <span style="color:#ff79c6">=</span> torch<span style="color:#ff79c6">.</span>stack(targets_list)
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">return</span> inputs_tensor, targets_tensor
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> functools <span style="color:#ff79c6">import</span> partial
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>customized_collate_fn <span style="color:#ff79c6">=</span> partial(
</span></span><span style="display:flex;"><span>    custom_collate_fn,
</span></span><span style="display:flex;"><span>    allowed_max_length<span style="color:#ff79c6">=</span><span style="color:#bd93f9">1024</span>
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><h3 id="3-创建数据加载器">3. 创建数据加载器</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>train_dataset <span style="color:#ff79c6">=</span> InstructionDataset(train_data, tokenizer)
</span></span><span style="display:flex;"><span>train_loader <span style="color:#ff79c6">=</span> DataLoader(
</span></span><span style="display:flex;"><span>    train_dataset,
</span></span><span style="display:flex;"><span>    batch_size<span style="color:#ff79c6">=</span>batch_size,
</span></span><span style="display:flex;"><span>    shuffle<span style="color:#ff79c6">=</span><span style="color:#ff79c6">True</span>,
</span></span><span style="display:flex;"><span>    num_workers<span style="color:#ff79c6">=</span>num_workers,
</span></span><span style="display:flex;"><span>    collate_fn<span style="color:#ff79c6">=</span>customized_collate_fn
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><h2 id="第二阶段模型微调">第二阶段：模型微调</h2>
<h3 id="1-模型初始化">1. 模型初始化</h3>
<p>使用在《徒手组装GPT》章节中构建的 GPTModel 类。这里建议使用较大的模型，因为小模型的指令遵循能力通常较弱。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>BASE_CONFIG  <span style="color:#ff79c6">=</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#f1fa8c">&#34;vocab_size&#34;</span>: <span style="color:#bd93f9">50257</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#f1fa8c">&#34;context_length&#34;</span>: <span style="color:#bd93f9">1024</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#f1fa8c">&#34;drop_rate&#34;</span>: <span style="color:#bd93f9">0.0</span>,
</span></span><span style="display:flex;"><span>    <span style="color:#f1fa8c">&#34;qkv_bias&#34;</span>: <span style="color:#ff79c6">True</span>
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>models_config <span style="color:#ff79c6">=</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#f1fa8c">&#34;gpt2&#34;</span>: {<span style="color:#f1fa8c">&#34;emb_dim&#34;</span>:<span style="color:#bd93f9">768</span>,<span style="color:#f1fa8c">&#34;n_heads&#34;</span>:<span style="color:#bd93f9">12</span>, <span style="color:#f1fa8c">&#34;n_layers&#34;</span>:<span style="color:#bd93f9">12</span>,},
</span></span><span style="display:flex;"><span>    <span style="color:#f1fa8c">&#34;gpt2-medium&#34;</span>: {<span style="color:#f1fa8c">&#34;emb_dim&#34;</span>:<span style="color:#bd93f9">1024</span>,<span style="color:#f1fa8c">&#34;n_heads&#34;</span>:<span style="color:#bd93f9">16</span>, <span style="color:#f1fa8c">&#34;n_layers&#34;</span>:<span style="color:#bd93f9">24</span>,},
</span></span><span style="display:flex;"><span>    <span style="color:#f1fa8c">&#34;gpt2-large&#34;</span>: {<span style="color:#f1fa8c">&#34;emb_dim&#34;</span>:<span style="color:#bd93f9">1280</span>,<span style="color:#f1fa8c">&#34;n_heads&#34;</span>:<span style="color:#bd93f9">20</span>, <span style="color:#f1fa8c">&#34;n_layers&#34;</span>:<span style="color:#bd93f9">36</span>,},
</span></span><span style="display:flex;"><span>    <span style="color:#f1fa8c">&#34;gpt2-xl&#34;</span>: {<span style="color:#f1fa8c">&#34;emb_dim&#34;</span>:<span style="color:#bd93f9">1600</span>,<span style="color:#f1fa8c">&#34;n_heads&#34;</span>:<span style="color:#bd93f9">25</span>, <span style="color:#f1fa8c">&#34;n_layers&#34;</span>:<span style="color:#bd93f9">48</span>,},
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>CHOOSE_MODEL<span style="color:#ff79c6">=</span> <span style="color:#f1fa8c">&#34;gpt2-xl&#34;</span>
</span></span><span style="display:flex;"><span>BASE_CONFIG<span style="color:#ff79c6">.</span>update(models_config[CHOOSE_MODEL])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model_size <span style="color:#ff79c6">=</span> CHOOSE_MODEL<span style="color:#ff79c6">.</span>split(<span style="color:#f1fa8c">&#34; &#34;</span>)[<span style="color:#ff79c6">-</span><span style="color:#bd93f9">1</span>]<span style="color:#ff79c6">.</span>lstrip(<span style="color:#f1fa8c">&#34;(&#34;</span>)<span style="color:#ff79c6">.</span>rstrip(<span style="color:#f1fa8c">&#34;)&#34;</span>)
</span></span><span style="display:flex;"><span>model <span style="color:#ff79c6">=</span> GPTModel(BASE_CONFIG)
</span></span></code></pre></div><h3 id="2-加载预训练权重">2. 加载预训练权重</h3>
<p>这部分在之前的章节中已经实现过：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>params <span style="color:#ff79c6">=</span> build_openai_numpy_dict(CHOOSE_MODEL)
</span></span><span style="display:flex;"><span>load_weights_into_gpt(model, params)
</span></span><span style="display:flex;"><span>model<span style="color:#ff79c6">.</span>eval()
</span></span></code></pre></div><h3 id="3-看模型微调之前的结果和loss">3. 看模型微调之前的结果和loss</h3>
<p>输入文本为：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>Below <span style="color:#ff79c6">is</span> an instruction that describes a task<span style="color:#ff79c6">.</span> Write a response that appropriately completes the request<span style="color:#ff79c6">.</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4">### Instruction:</span>
</span></span><span style="display:flex;"><span>Rewrite the sentence using a simile<span style="color:#ff79c6">.</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4">### Input:</span>
</span></span><span style="display:flex;"><span>The car <span style="color:#ff79c6">is</span> very fast<span style="color:#ff79c6">.</span>
</span></span></code></pre></div><p>模型回复为：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>dividendJenn Growing clans readspar goodness264264 Monthescap woes Neither experienced Surprisinglyortalityonductorassies Athletics Anniversary descriptive descriptive biases rookies Neither Ming Isleneapolis endors Height outreach floods LU Part
</span></span></code></pre></div><p>可以看出，未经微调的大语言模型还不能正确遵循指令，只能进行文本补全。</p>
<p>初始损失为：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>Training loss: <span style="color:#bd93f9">10.981371307373047</span>
</span></span><span style="display:flex;"><span>Validation loss: <span style="color:#bd93f9">10.983566093444825</span>
</span></span></code></pre></div><h3 id="4--训练代码实现">4 . 训练代码实现</h3>
<p>在每次循环中，我们计算每个训练批次的损失，获取梯度，并用其更新模型权重，从而逐步降低训练损失。</p>
<p>计算模型损失</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#ff79c6">def</span> <span style="color:#50fa7b">calc_loss_batch</span>(input_batch, output_batch, model, device):
</span></span><span style="display:flex;"><span>    input_batch <span style="color:#ff79c6">=</span> input_batch<span style="color:#ff79c6">.</span>to(device)
</span></span><span style="display:flex;"><span>    output_batch <span style="color:#ff79c6">=</span> output_batch<span style="color:#ff79c6">.</span>to(device)
</span></span><span style="display:flex;"><span>    logits <span style="color:#ff79c6">=</span> model(input_batch)
</span></span><span style="display:flex;"><span>    loss <span style="color:#ff79c6">=</span> torch<span style="color:#ff79c6">.</span>nn<span style="color:#ff79c6">.</span>functional<span style="color:#ff79c6">.</span>cross_entropy(logits<span style="color:#ff79c6">.</span>flatten(<span style="color:#bd93f9">0</span>,<span style="color:#bd93f9">1</span>), output_batch<span style="color:#ff79c6">.</span>flatten())
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">return</span> loss
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">def</span> <span style="color:#50fa7b">calc_loss_loader</span>(data_loader, model, device, num_batches<span style="color:#ff79c6">=</span><span style="color:#ff79c6">None</span>):
</span></span><span style="display:flex;"><span>    total_loss <span style="color:#ff79c6">=</span><span style="color:#bd93f9">0.0</span>
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">if</span> <span style="color:#8be9fd;font-style:italic">len</span>(data_loader) <span style="color:#ff79c6">==</span> <span style="color:#bd93f9">0</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">return</span> <span style="color:#8be9fd;font-style:italic">float</span>(<span style="color:#f1fa8c">&#34;nan&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">elif</span> num_batches <span style="color:#ff79c6">is</span> <span style="color:#ff79c6">None</span>:
</span></span><span style="display:flex;"><span>        num_batches <span style="color:#ff79c6">=</span><span style="color:#8be9fd;font-style:italic">len</span>(data_loader)
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">else</span>:
</span></span><span style="display:flex;"><span>        num_batches <span style="color:#ff79c6">=</span> <span style="color:#8be9fd;font-style:italic">min</span>(num_batches, <span style="color:#8be9fd;font-style:italic">len</span>(data_loader))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">for</span> i, (input_batch, target_batch) <span style="color:#ff79c6">in</span> <span style="color:#8be9fd;font-style:italic">enumerate</span>(data_loader):
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">if</span> i <span style="color:#ff79c6">&lt;</span> num_batches:
</span></span><span style="display:flex;"><span>            loss <span style="color:#ff79c6">=</span> calc_loss_batch(input_batch, target_batch, model, device)
</span></span><span style="display:flex;"><span>            total_loss <span style="color:#ff79c6">+=</span> loss<span style="color:#ff79c6">.</span>item()
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">else</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#ff79c6">break</span>
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">return</span> total_loss <span style="color:#ff79c6">/</span> num_batches
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">def</span> <span style="color:#50fa7b">evaluate_model</span>(model, train_loader,val_loader,device,eval_iter):
</span></span><span style="display:flex;"><span>    model<span style="color:#ff79c6">.</span>eval()
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">with</span> torch<span style="color:#ff79c6">.</span>no_grad():
</span></span><span style="display:flex;"><span>        train_loss <span style="color:#ff79c6">=</span> calc_loss_loader(train_loader, model, device, num_batches<span style="color:#ff79c6">=</span>eval_iter)
</span></span><span style="display:flex;"><span>        val_loss <span style="color:#ff79c6">=</span> calc_loss_loader(val_loader, model, device, num_batches<span style="color:#ff79c6">=</span>eval_iter)
</span></span><span style="display:flex;"><span>    model<span style="color:#ff79c6">.</span>train()
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">return</span> train_loss, val_loss
</span></span></code></pre></div><p>训练步骤</p>
<ol>
<li>遍历训练轮次（一轮就是完整地遍历一次训练集）</li>
<li>在每个训练轮次中遍历批次（批次数量由训练集大小除以每个批次的大小确定）</li>
<li>从上一个批次迭代中重置损失函数</li>
<li>计算当前批次的损失</li>
<li>反向传播以计算损失梯度</li>
<li>使用损失梯度更新模型权重</li>
<li>打印训练集和验证集的损失（可选）</li>
</ol>
<p>训练代码</p>
<p>代码很好写，就是上面的七个步骤：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#ff79c6">def</span> <span style="color:#50fa7b">train_model_simple</span>(model, train_loader, val_loader,
</span></span><span style="display:flex;"><span>                       optimizer, device, num_epochs,
</span></span><span style="display:flex;"><span>                       eval_freq, eval_iter, start_context, tokenizer):
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    train_losses, val_losses, track_tokens_seen <span style="color:#ff79c6">=</span> [], [], []
</span></span><span style="display:flex;"><span>    tokens_seen, global_step <span style="color:#ff79c6">=</span> <span style="color:#bd93f9">0</span>, <span style="color:#ff79c6">-</span><span style="color:#bd93f9">1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">for</span> epoch <span style="color:#ff79c6">in</span> <span style="color:#8be9fd;font-style:italic">range</span>(num_epochs):
</span></span><span style="display:flex;"><span>        model<span style="color:#ff79c6">.</span>train()                     
</span></span><span style="display:flex;"><span> 
</span></span><span style="display:flex;"><span>        <span style="color:#ff79c6">for</span> input_batch, target_batch <span style="color:#ff79c6">in</span> train_loader:
</span></span><span style="display:flex;"><span>            optimizer<span style="color:#ff79c6">.</span>zero_grad(set_to_none<span style="color:#ff79c6">=</span><span style="color:#ff79c6">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            loss <span style="color:#ff79c6">=</span> calc_loss_batch(input_batch, target_batch, model, device)
</span></span><span style="display:flex;"><span>            loss<span style="color:#ff79c6">.</span>backward()
</span></span><span style="display:flex;"><span>            optimizer<span style="color:#ff79c6">.</span>step()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            tokens_seen <span style="color:#ff79c6">+=</span> input_batch<span style="color:#ff79c6">.</span>numel()
</span></span><span style="display:flex;"><span>            global_step <span style="color:#ff79c6">+=</span> <span style="color:#bd93f9">1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            <span style="color:#6272a4"># --- periodic evaluation ---</span>
</span></span><span style="display:flex;"><span>            <span style="color:#ff79c6">if</span> global_step <span style="color:#ff79c6">%</span> eval_freq <span style="color:#ff79c6">==</span> <span style="color:#bd93f9">0</span>:
</span></span><span style="display:flex;"><span>                train_loss, val_loss <span style="color:#ff79c6">=</span> evaluate_model(
</span></span><span style="display:flex;"><span>                    model, train_loader, val_loader, device, eval_iter)
</span></span><span style="display:flex;"><span>                train_losses<span style="color:#ff79c6">.</span>append(train_loss)
</span></span><span style="display:flex;"><span>                val_losses<span style="color:#ff79c6">.</span>append(val_loss)
</span></span><span style="display:flex;"><span>                track_tokens_seen<span style="color:#ff79c6">.</span>append(tokens_seen)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                <span style="color:#8be9fd;font-style:italic">print</span>(<span style="color:#f1fa8c">f</span><span style="color:#f1fa8c">&#34;Ep </span><span style="color:#f1fa8c">{</span>epoch <span style="color:#ff79c6">+</span> <span style="color:#bd93f9">1</span><span style="color:#f1fa8c">}</span><span style="color:#f1fa8c"> (step </span><span style="color:#f1fa8c">{</span>global_step<span style="color:#f1fa8c">:</span><span style="color:#f1fa8c">06d</span><span style="color:#f1fa8c">}</span><span style="color:#f1fa8c">): &#34;</span>
</span></span><span style="display:flex;"><span>                      <span style="color:#f1fa8c">f</span><span style="color:#f1fa8c">&#34;train loss </span><span style="color:#f1fa8c">{</span>train_loss<span style="color:#f1fa8c">:</span><span style="color:#f1fa8c">.3f</span><span style="color:#f1fa8c">}</span><span style="color:#f1fa8c">, val loss </span><span style="color:#f1fa8c">{</span>val_loss<span style="color:#f1fa8c">:</span><span style="color:#f1fa8c">.3f</span><span style="color:#f1fa8c">}</span><span style="color:#f1fa8c">&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    save_dir <span style="color:#ff79c6">=</span> <span style="color:#f1fa8c">&#34;results/plots&#34;</span>
</span></span><span style="display:flex;"><span>    os<span style="color:#ff79c6">.</span>makedirs(save_dir, exist_ok<span style="color:#ff79c6">=</span><span style="color:#ff79c6">True</span>)
</span></span><span style="display:flex;"><span>    plot_path <span style="color:#ff79c6">=</span> os<span style="color:#ff79c6">.</span>path<span style="color:#ff79c6">.</span>join(save_dir, <span style="color:#f1fa8c">f</span><span style="color:#f1fa8c">&#34;training_loss_plot_</span><span style="color:#f1fa8c">{</span>CHOOSE_MODEL<span style="color:#f1fa8c">}</span><span style="color:#f1fa8c">.png&#34;</span>)
</span></span><span style="display:flex;"><span>    epochs_tensor <span style="color:#ff79c6">=</span> torch<span style="color:#ff79c6">.</span>linspace(<span style="color:#bd93f9">0</span>, num_epochs, <span style="color:#8be9fd;font-style:italic">len</span>(train_losses))
</span></span><span style="display:flex;"><span>    plot_losses(epochs_tensor, track_tokens_seen, train_losses, val_losses,save_path<span style="color:#ff79c6">=</span>plot_path)
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>    <span style="color:#ff79c6">return</span> train_losses, val_losses, track_tokens_seen
</span></span></code></pre></div><p>运行训练</p>
<p>由于使用的是 gpt2-xl 模型，使用多张 GPU 运行以避免内存不足：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>CUDA_VISIBLE_DEVICES<span style="color:#ff79c6">=</span><span style="color:#bd93f9">2</span>,<span style="color:#bd93f9">3</span>,<span style="color:#bd93f9">5</span> python <span style="color:#ff79c6">/</span>home<span style="color:#ff79c6">/</span>data<span style="color:#ff79c6">/</span>sophia<span style="color:#ff79c6">/</span>learning_llm<span style="color:#ff79c6">/</span>llm_from_scratch<span style="color:#ff79c6">/</span>chapter_7
</span></span><span style="display:flex;"><span>_instruct_tuning<span style="color:#ff79c6">/</span>finetune<span style="color:#ff79c6">.</span>py
</span></span></code></pre></div><p>下图展示了训练两个 epoch 后的损失曲线。实线表示训练损失，呈现快速下降后趋于稳定的趋势；虚线表示验证损失，模式类似，说明模型训练是有效的。</p>
<p><img src="https://raw.githubusercontent.com/HuizhiXu/pictures/master/20251101/4c784609.png"></p>
<p>在新数据上使用模型进行推理</p>
<p>虽然模型没有回答正确，但回复的格式和内容已经比微调前规范许多。</p>
<h2 id="第三阶段评估大语言模型">第三阶段：评估大语言模型</h2>
<p>常见的模型评估方法是基于公开基准数据集进行测试。此外，也可以使用另一个大语言模型（例如通过 ollama 启动的 Llama 3）对测试数据进行自动评估。</p>
<p>书中对此有具体示例，这里不再赘述。</p>

  </article>
<div class="px-2 mb-2">
  
  <script src="https://utteranc.es/client.js"
    repo="HuizhiXu/huizhixu.github.io"
    issue-term="pathname"
    theme="github-light"
    crossorigin="anonymous"
    async>
  </script>
  
</div>
<div class="bg-blue-100 dark:bg-gray-900">
  <div class="container px-4 py-12 mx-auto max-w-4xl grid grid-cols-1 md:grid-cols-2 gap-4 items-center">
    <div>
      <div class="text-2xl font-bold mb-2">Sein heißt werden, leben heißt lernen.</div>
      <p class="opacity-60">Der einfache Weg is immer verkehrt.</p>
    </div>

    <ul class="flex justify-center gap-x-3 flex-wrap gap-y-2">
      

      
      <li>
        <a
          href="https://twitter.com/"
          target="_blank"
          rel="noopener"
          aria-label="Twitter"
          class="p-1 inline-block rounded-full border border-transparent text-gray-500 hover:text-gray-800 hover:border-gray-800 cursor-pointer transition-colors dark:text-gray-600 dark:hover:border-gray-300 dark:hover:text-gray-300"
        >
          <svg
            xmlns="http://www.w3.org/2000/svg"
            width="24"
            height="24"
            viewBox="0 0 24 24"
            stroke-width="1.5"
            stroke="currentColor"
            fill="none"
            stroke-linecap="round"
            stroke-linejoin="round"
          >
            <path stroke="none" d="M0 0h24v24H0z" fill="none" />
            <path
              d="M22 4.01c-1 .49 -1.98 .689 -3 .99c-1.121 -1.265 -2.783 -1.335 -4.38 -.737s-2.643 2.06 -2.62 3.737v1c-3.245 .083 -6.135 -1.395 -8 -4c0 0 -4.182 7.433 4 11c-1.872 1.247 -3.739 2.088 -6 2c3.308 1.803 6.913 2.423 10.034 1.517c3.58 -1.04 6.522 -3.723 7.651 -7.742a13.84 13.84 0 0 0 .497 -3.753c-.002 -.249 1.51 -2.772 1.818 -4.013z"
            />
          </svg>
        </a>
      </li>
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      
      <li>
        <a
          href="https://github.com/"
          target="_blank"
          rel="noopener"
          aria-label="GitHub"
          class="p-1 inline-block rounded-full border border-transparent text-gray-500 hover:text-gray-800 hover:border-gray-800 cursor-pointer transition-colors dark:text-gray-600 dark:hover:border-gray-300 dark:hover:text-gray-300"
        >
          <svg
            xmlns="http://www.w3.org/2000/svg"
            width="24"
            height="24"
            viewBox="0 0 24 24"
            stroke-width="1.5"
            stroke="currentColor"
            fill="none"
            stroke-linecap="round"
            stroke-linejoin="round"
          >
            <path stroke="none" d="M0 0h24v24H0z" fill="none" />
            <path
              d="M9 19c-4.3 1.4 -4.3 -2.5 -6 -3m12 5v-3.5c0 -1 .1 -1.4 -.5 -2c2.8 -.3 5.5 -1.4 5.5 -6a4.6 4.6 0 0 0 -1.3 -3.2a4.2 4.2 0 0 0 -.1 -3.2s-1.1 -.3 -3.5 1.3a12.3 12.3 0 0 0 -6.2 0c-2.4 -1.6 -3.5 -1.3 -3.5 -1.3a4.2 4.2 0 0 0 -.1 3.2a4.6 4.6 0 0 0 -1.3 3.2c0 4.6 2.7 5.7 5.5 6c-.6 .6 -.6 1.2 -.5 2v3.5"
            />
          </svg>
        </a>
      </li>
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      
    </ul>
  </div>
</div>

    </main><footer class="container p-6 mx-auto flex justify-between items-center">
  <span class="text-sm font-light">
    
    Copyright © 2012 - Huizhi Xu · All rights reserved
    
  </span>
  <span onclick="window.scrollTo({top: 0, behavior: 'smooth'})" class="p-1 cursor-pointer">
    <svg xmlns="http://www.w3.org/2000/svg" width="30" height="30" viewBox="0 0 24 24" stroke-width="1.5"
      stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M18 15l-6 -6l-6 6h12" />
    </svg>
  </span>
</footer>

<div class="search-ui absolute top-0 left-0 w-full h-full bg-white dark:bg-gray-800 hidden">
  <div class="container max-w-3xl mx-auto p-12">
    <div class="relative">
      <div class="my-4 text-center text-2xl font-bold">Search</div>

      <span class="p-2 absolute right-0 top-0 cursor-pointer close-search">
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" stroke-width="1.5"
          stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
          <path stroke="none" d="M0 0h24v24H0z" fill="none" />
          <line x1="18" y1="6" x2="6" y2="18" />
          <line x1="6" y1="6" x2="18" y2="18" />
        </svg>
      </span>
    </div>

    <input type="search" class="py-2 px-3 w-full dark:text-black border dark:border-transparent"
      placeholder="Enter search query" />

    <div class="search-results text-lg font-medium my-4 hidden">Results</div>
    <ul class="search-list my-2">

    </ul>

    <div class="no-results text-center my-8 hidden">
      <div class="text-xl font-semibold mb-2">No results found</div>
      <p class="font-light text-sm">Try adjusting your search query</p>
    </div>
  </div>
</div>





<script src="https://huizhixu.github.io/js/scripts.min.js"></script>




<script>
  const languageMenuButton = document.querySelector('.language-switcher');
  const languageDropdown = document.querySelector('.language-dropdown');
  languageMenuButton.addEventListener('click', (evt) => {
    evt.preventDefault()
    if (languageDropdown.classList.contains('hidden')) {
      languageDropdown.classList.remove('hidden')
      languageDropdown.classList.add('flex')
    } else {
      languageDropdown.classList.add('hidden');
      languageDropdown.classList.remove('flex');
    }
  })
</script>



<script>
  
  const darkmode = document.querySelector('.toggle-dark-mode');
  function toggleDarkMode() {
    if (document.documentElement.classList.contains('dark')) {
      document.documentElement.classList.remove('dark')
      localStorage.setItem('darkmode', 'light')
    } else {
      document.documentElement.classList.add('dark')
      localStorage.setItem('darkmode', 'dark')
    }
  }
  if (darkmode) {
    darkmode.addEventListener('click', toggleDarkMode);
  }

  const darkStorage = localStorage.getItem('darkmode');
  const isBrowserDark = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;

  if (!darkStorage && isBrowserDark) {
    document.documentElement.classList.add('dark');
  }

  if (darkStorage && darkStorage === 'dark') {
    toggleDarkMode();
  }
</script>


<script>
  const mobileMenuButton = document.querySelector('.mobile-menu-button')
  const mobileMenu = document.querySelector('.mobile-menu')
  function toggleMenu() {
    mobileMenu.classList.toggle('hidden');
    mobileMenu.classList.toggle('flex');
  }
  if(mobileMenu && mobileMenuButton){
    mobileMenuButton.addEventListener('click', toggleMenu)
  }
</script>
</body>
</html>
